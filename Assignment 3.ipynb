{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\inpshy\\anaconda3\\lib\\site-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\inpshy\\anaconda3\\lib\\site-packages (from selenium) (1.25.11)\n"
     ]
    }
   ],
   "source": [
    "#lets install lhe selenium libariries\n",
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Importing selenium webdriver \n",
    "from selenium import webdriver\n",
    "\n",
    "# Importing required Exceptions which needs to handled\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "\n",
    "#Importing requests\n",
    "import requests\n",
    "\n",
    "# importing regex\n",
    "import re\n",
    "import urllib3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect with webdriver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\INPshy\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "#URL link\n",
    "url='https://www.amazon.in/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element_by_id('twotabsearchtextbox')\n",
    "search.send_keys('Watches')\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "watch=driver.find_element_by_id('nav-search-submit-button')\n",
    "watch.click()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand=[]\n",
    "Product_name=[]\n",
    "Rating=[]\n",
    "No_Rating=[]\n",
    "Price=[]\n",
    "Return=[]\n",
    "Expected_Delivery=[]\n",
    "Availbility=[]\n",
    "Other_details=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Product_Url=[]\n",
    "\n",
    "urls = driver.find_elements_by_xpath('//h2[@class=\"a-size-mini a-spacing-none a-color-base s-line-clamp-2\"]//a')\n",
    "for url in urls:\n",
    "    Product_Url.append(url.get_attribute(\"href\"))\n",
    "    time.sleep(2)    \n",
    "        \n",
    "try:\n",
    "    next_button = driver.find_element_by_xpath('//li[@class=\"a-selected\"]')\n",
    "    next_button.click()\n",
    "except:\n",
    "    continue\n",
    "    \n",
    "\n",
    "Brand=[]\n",
    "Product_name=[]\n",
    "Rating=[]\n",
    "No_Rating=[]\n",
    "Price=[]\n",
    "Return=[]\n",
    "Expected_Delivery=[]\n",
    "Availbility=[]\n",
    "Other_details=[]       \n",
    "for page in Product_Url[:2]:\n",
    "    driver.get(page)\n",
    "\n",
    "#fetch Brand\n",
    "try:\n",
    "    barnd=driver.find_elements_by_xpath('//div[@class=\"celwidget\"]')\n",
    "    Brand.append(brad.text)\n",
    "except NoSuchElementException:\n",
    "    \n",
    "    Brand.append('No Name')\n",
    "#fetch rating\n",
    "try:\n",
    "    rating=driver.find_elements_by_xpath('//div[@class=\"a-fixed-left-grid-col aok-align-center a-col-right\"]')\n",
    "    Rating.append(rating.text)\n",
    "except NoSuchElementException:\n",
    "    Rating.append('no rating')\n",
    "#fetch No of Rating\n",
    "try:\n",
    "    no_rating=driver.find_elements_by_xpath('//span[@class=\"a-declarative\"]')\n",
    "    No_Rating.append(no_rating.text)\n",
    "except NoSuchElementException:\n",
    "    No_Rating.append('NO Rating')\n",
    "    \n",
    "#fetch Price\n",
    "try:\n",
    "    price=driver.find_elements_by_xpath('//td[@class=\"a-span12\"]')\n",
    "    Price.append(price.text)\n",
    "except NoSuchElementException:\n",
    "    Price.append('-')\n",
    "#fetch return\n",
    "try:\n",
    "    retur=driver.find_elements_by_xpath('//div[@class=\"a-section a-spacing-none icon-content\"]')\n",
    "    Return.append(retur.text)\n",
    "except NoSuchElementException:\n",
    "    Return.append('-')\n",
    "#fetch delivery\n",
    "try:\n",
    "    delivery=driver.find_elements_by_xpath('//*[@id=\"ddmDeliveryMessage\"]/b')\n",
    "    Expected_Delivery.append(delivery.text)\n",
    "except NoSuchElementException:\n",
    "    Expected_Delivery.append('-')\n",
    "   \n",
    "#fetch Avilbility\n",
    "try:\n",
    "    avial=driver.find_elements_by_xpath('//div[@class=\"celwidget\"]/div/span')\n",
    "    Availbility.append(avial.text)\n",
    "except NoSuchElementException:\n",
    "    \n",
    "    Availbility.append('-')\n",
    "#fetch other details\n",
    "    \n",
    "try:\n",
    "    other=driver.find_elements_by_xpath('//ul[@class=\"a-unordered-list a-vertical a-spacing-mini\"]')\n",
    "    Other_details.append(other.text)\n",
    "except NoSuchElementException:\n",
    "    Other_details.append('-')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand=[]\n",
    "Product_name=[]\n",
    "Rating=[]\n",
    "No_Rating=[]\n",
    "Price=[]\n",
    "Return=[]\n",
    "Expected_Deleiry=[]\n",
    "Availbility=[]\n",
    "Other_details=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2.6 out of 5', '4 out of 5', '4.4 out of 5', '4.6 out of 5', '4 out of 5']\n"
     ]
    }
   ],
   "source": [
    "for i in Product_Url[:5]:\n",
    "    driver.get(i)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        rating=driver.find_elements_by_xpath('//*[@id=\"reviewsMedley\"]/div/div[1]/div[2]/div[1]/div/div[2]/div/span')\n",
    "        for o in rating:\n",
    "            Rating.append(o.text)\n",
    "    except NoSuchElementException:\n",
    "        Rating.append('-')\n",
    "print(Rating)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10 Days Returns', '7 Days Replacement', '10 Days Returns']\n"
     ]
    }
   ],
   "source": [
    "Return=[]\n",
    "for i in Product_Url[:3]:\n",
    "    driver.get(i)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        return_item=driver.find_elements_by_xpath('/html/body/div[2]/div[2]/div[5]/div[1]/div[1]/div[2]/div[2]/div/div/div[1]/div[12]/div[2]/div/div/div/div[2]/span/div[2]/a')\n",
    "        for o in return_item:\n",
    "            Return.append(o.text)\n",
    "    except NoSuchElementException:\n",
    "        Return.append('-')\n",
    "print(Return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Swissam', 'Tommy Hilfiger']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Brand=[]\n",
    "for i in Product_Url[:5]:\n",
    "    driver.get(i)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        brand=driver.find_elements_by_xpath('/html/body/div[2]/div[2]/div[5]/div[14]/div/div/div[1]/ul/li[4]/span/span[2]')\n",
    "        for j in brand:\n",
    "            Brand.append(j.text)\n",
    "    except NoSuchElementException:\n",
    "        Brand.append('-')\n",
    "Brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3 ratings', '1 rating', '23 ratings']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "No_Rating=[]\n",
    "for i in Product_Url[:3]:\n",
    "    driver.get(i)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        other_details=driver.find_elements_by_xpath('/html/body/div[2]/div[2]/div[5]/div[1]/div[1]/div[2]/div[2]/div/div/div[1]/div[1]/div[2]/div[4]/div/span[3]/a')\n",
    "        for p in other_details:\n",
    "            No_Rating.append(p.text)\n",
    "    except NoSuchElementException:\n",
    "        No_Rating.append('-')\n",
    "No_Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.amazon.in/stores/TOMMY+HILFIGER+TRAVEL+GEAR/page/70C108DB-9462-44EB-99FC-9472622107CC?ref_=ast_bln',\n",
       " 'https://www.amazon.in/stores/TOMMY+HILFIGER+TRAVEL+GEAR/page/70C108DB-9462-44EB-99FC-9472622107CC?ref_=ast_bln',\n",
       " 'https://www.amazon.in/stores/TOMMY+HILFIGER+TRAVEL+GEAR/page/70C108DB-9462-44EB-99FC-9472622107CC?ref_=ast_bln']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Product_URL=[]\n",
    "for i in Product_Url[:3]:\n",
    "    driver.get(i)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    try:\n",
    "        url=driver.find_elements_by_xpath('//div[@class=\"a-section a-spacing-none\"]/a')\n",
    "        for i in url:\n",
    "            Product_URL.append(i.get_attribute('href'))\n",
    "    except NoSuchElementException:\n",
    "        Product_URL.append('-')\n",
    "Product_URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In stock.', 'In stock.', 'In stock.']\n"
     ]
    }
   ],
   "source": [
    "Availbility=[]\n",
    "for i in Product_Url[:3]:\n",
    "    driver.get(i)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        avail=driver.find_elements_by_xpath('/html/body/div[2]/div[2]/div[5]/div[1]/div[1]/div[2]/div[2]/div/div/div[1]/div[14]/div[1]/span')\n",
    "        for p in avail:\n",
    "            Availbility.append(p.text)\n",
    "    except NoSuchElementException:\n",
    "        Availbility.append('-')\n",
    "print(Availbility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in Product_Url[:10]:\n",
    "    driver.get(i)\n",
    "    time.sleep(2)\n",
    "    #fetch brand\n",
    "    try:\n",
    "        brand=driver.find_elements_by_xpath('/html/body/div[2]/div[2]/div[5]/div[14]/div/div/div[1]/ul/li[4]/span/span[2]')\n",
    "        for j in brand:\n",
    "            Brand.append(j.text)\n",
    "    except NoSuchElementException:\n",
    "        Brand.append('-')\n",
    "    #fetch Product_name\n",
    "    try:\n",
    "        product=driver.find_elements_by_xpath('/html/body/div[2]/div[2]/div[5]/div[1]/div[1]/div[2]/div[2]/div/div/div[1]/div[1]/div[2]/div[1]/div/h1/span')\n",
    "        for k in product:\n",
    "            Product_name.append(k.text)\n",
    "    except NoSuchElementException:\n",
    "        Product_name.append('-')\n",
    "    #fetch Rating\n",
    "    try:\n",
    "        rating=driver.find_elements_by_xpath('/html/body/div[2]/div[2]/div[5]/div[17]/div/div[1]/div[2]/div[1]/div/div[2]/div/span/span')\n",
    "        for l in rating:\n",
    "            Rating.append(l.text)\n",
    "    except NoSuchElementException:\n",
    "        Rating.append('-')\n",
    "    #fetch No_rating\n",
    "    \n",
    "    try:\n",
    "        no_rating=driver.find_elements_by_xpath('/html/body/div[2]/div[2]/div[5]/div[1]/div[1]/div[2]/div[2]/div/div/div[1]/div[1]/div[2]/div[4]/div/span[3]/a/span')\n",
    "        for l in no_rating:\n",
    "            No_Rating.append(l.text)\n",
    "    except NoSuchElementException:\n",
    "        No_Rating.append('-')\n",
    "    #fetch Price\n",
    "    try:\n",
    "        price=driver.find_elements_by_xpath('/html/body/div[2]/div[2]/div[5]/div[1]/div[1]/div[2]/div[2]/div/div/div[1]/div[2]/div/div/table/tbody/tr[1]/td[2]/span[1]')\n",
    "        for m in price:\n",
    "            Price.append(m.text)\n",
    "    except NoSuchElementException:\n",
    "        Price.append('-')\n",
    "    #fetch Return\n",
    "    try:\n",
    "        return_item=driver.find_elements_by_xpath('/html/body/div[2]/div[2]/div[5]/div[1]/div[1]/div[2]/div[2]/div/div/div[1]/div[12]/div[2]/div/div/div/div[2]/span/div[2]/a')\n",
    "        for n in return_item:\n",
    "            Return.append(n.text)\n",
    "    except NoSuchElementException:\n",
    "        Return.append('-')\n",
    "    #fetch Expeceted delivery date\n",
    "    try:\n",
    "        expt_date=driver.find_elements_by_xpath('/html/body/div[2]/div[2]/div[5]/div[1]/div[1]/div[2]/div[2]/div/div/div[1]/div[4]/div/div/b')\n",
    "        for o in expt_date:\n",
    "            Expected_Deleiry.append(o.text)\n",
    "    except NoSuchElementException:\n",
    "        Expected_Deleiry.append('-')\n",
    "        \n",
    "    #other details\n",
    "    try:\n",
    "        other=driver.find_elements_by_xpath('/html/body/div[2]/div[2]/div[5]/div[1]/div[1]/div[2]/div[2]/div/div/div[1]/div[28]/div/ul')\n",
    "        for p in other:\n",
    "            Other_details.append(p.text)\n",
    "    except NoSuchElementException:\n",
    "        Other_details.append('-')\n",
    "    #fetch Avialbility\n",
    "    try:\n",
    "        avail=driver.find_elements_by_xpath('/html/body/div[2]/div[2]/div[5]/div[1]/div[1]/div[2]/div[2]/div/div/div[1]/div[15]/div[1]/span')\n",
    "        for q in avail:\n",
    "            Availbility.append(q.text)\n",
    "    except NoSuchElementException:\n",
    "        Availbility.append('-')\n",
    "   #fetch Product_URL\n",
    "    \n",
    "    try:\n",
    "        url=driver.find_elements_by_xpath('//div[@class=\"a-section a-spacing-none\"]/a')\n",
    "        for i in url:\n",
    "            Product_URL.append(i.get_attribute('href'))\n",
    "    except NoSuchElementException:\n",
    "        Product_URL.append('-')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 6 3 6 6 5 6 5 6\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand),len(Product_name),len(Rating),len(No_Rating),len(Price),len(Return),len(Expected_Deleiry),len(Other_details),len(Availbility))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#question 3\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\INPshy\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.google.com/imghp?hl=en'\n",
    "driver.get(url)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "searc_fruits=driver.find_element_by_xpath('//input[@class=\"gLFyf gsfi\"]')\n",
    "searc_fruits.send_keys('fruits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "click_fruit=driver.find_element_by_xpath('//span[@class=\"z1asCe MZy1Rb\"]')\n",
    "click_fruit.click()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 0 of 100 images\n",
      "Downloading 1 of 100 images\n",
      "Downloading 2 of 100 images\n",
      "Downloading 3 of 100 images\n",
      "Downloading 4 of 100 images\n",
      "Downloading 5 of 100 images\n",
      "Downloading 6 of 100 images\n",
      "Downloading 7 of 100 images\n",
      "Downloading 8 of 100 images\n",
      "Downloading 9 of 100 images\n",
      "Downloading 10 of 100 images\n",
      "Downloading 11 of 100 images\n",
      "Downloading 12 of 100 images\n",
      "Downloading 13 of 100 images\n",
      "Downloading 14 of 100 images\n",
      "Downloading 15 of 100 images\n",
      "Downloading 16 of 100 images\n",
      "Downloading 17 of 100 images\n",
      "Downloading 18 of 100 images\n",
      "Downloading 19 of 100 images\n",
      "Downloading 20 of 100 images\n",
      "Downloading 21 of 100 images\n",
      "Downloading 22 of 100 images\n",
      "Downloading 23 of 100 images\n",
      "Downloading 24 of 100 images\n",
      "Downloading 25 of 100 images\n",
      "Downloading 26 of 100 images\n",
      "Downloading 27 of 100 images\n",
      "Downloading 28 of 100 images\n",
      "Downloading 29 of 100 images\n",
      "Downloading 30 of 100 images\n",
      "Downloading 31 of 100 images\n",
      "Downloading 32 of 100 images\n",
      "Downloading 33 of 100 images\n",
      "Downloading 34 of 100 images\n",
      "Downloading 35 of 100 images\n",
      "Downloading 36 of 100 images\n",
      "Downloading 37 of 100 images\n",
      "Downloading 38 of 100 images\n",
      "Downloading 39 of 100 images\n",
      "Downloading 40 of 100 images\n",
      "Downloading 41 of 100 images\n",
      "Downloading 42 of 100 images\n",
      "Downloading 43 of 100 images\n",
      "Downloading 44 of 100 images\n",
      "Downloading 45 of 100 images\n",
      "Downloading 46 of 100 images\n",
      "Downloading 47 of 100 images\n",
      "Downloading 48 of 100 images\n",
      "Downloading 49 of 100 images\n",
      "Downloading 50 of 100 images\n",
      "Downloading 51 of 100 images\n",
      "Downloading 52 of 100 images\n",
      "Downloading 53 of 100 images\n",
      "Downloading 54 of 100 images\n",
      "Downloading 55 of 100 images\n",
      "Downloading 56 of 100 images\n",
      "Downloading 57 of 100 images\n",
      "Downloading 58 of 100 images\n",
      "Downloading 59 of 100 images\n",
      "Downloading 60 of 100 images\n",
      "Downloading 61 of 100 images\n",
      "Downloading 62 of 100 images\n",
      "Downloading 63 of 100 images\n",
      "Downloading 64 of 100 images\n",
      "Downloading 65 of 100 images\n",
      "Downloading 66 of 100 images\n",
      "Downloading 67 of 100 images\n",
      "Downloading 68 of 100 images\n",
      "Downloading 69 of 100 images\n",
      "Downloading 70 of 100 images\n",
      "Downloading 71 of 100 images\n",
      "Downloading 72 of 100 images\n",
      "Downloading 73 of 100 images\n",
      "Downloading 74 of 100 images\n",
      "Downloading 75 of 100 images\n"
     ]
    }
   ],
   "source": [
    "# Activating the chrome browser (Fruits)\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(3)\n",
    "\n",
    "# Opening the google images\n",
    "url = \"https://images.google.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "search_bar = driver.find_element_by_xpath('//*[@id=\"sbtc\"]/div/div[2]/input')    # Finding the search bar using it's xpath\n",
    "search_bar.send_keys(\"fruits\")       # Inputing \"fruits\" keyword to search images\n",
    "search_button = driver.find_element_by_xpath('//*[@id=\"sbtc\"]/button')    # Finding the xpath of search button\n",
    "search_button.click()        # Clicking the search button\n",
    "time.sleep(8)\n",
    "\n",
    "# 500 time we scroll down by 10000 in order to generate more images on the website\n",
    "for _ in range(500):\n",
    "    driver.execute_script(\"window.scrollBy(0,10000)\")\n",
    "    \n",
    "images = driver.find_elements_by_xpath('//img[@class=\"rg_i Q4LuWd\"]')\n",
    "\n",
    "img_urls = []\n",
    "img_data = []\n",
    "for image in images:\n",
    "    source= image.get_attribute('src')\n",
    "    if source is not None:\n",
    "        if(source[0:4] == 'http'):\n",
    "            img_urls.append(source)\n",
    "            \n",
    "            \n",
    "for i in range(len(img_urls)):\n",
    "    if i >= 100:\n",
    "        break\n",
    "    print(\"Downloading {0} of {1} images\" .format(i, 100))\n",
    "    response= requests.get(img_urls[i])\n",
    "    file = open(r\"C:\\Users\\INPshy\\Desktop\\DATA Science\\Fruits img\\Fruits\"+str(i)+\".jpg\", \"wb\")\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 0 of 100 images\n",
      "Downloading 1 of 100 images\n",
      "Downloading 2 of 100 images\n",
      "Downloading 3 of 100 images\n",
      "Downloading 4 of 100 images\n",
      "Downloading 5 of 100 images\n",
      "Downloading 6 of 100 images\n",
      "Downloading 7 of 100 images\n",
      "Downloading 8 of 100 images\n",
      "Downloading 9 of 100 images\n",
      "Downloading 10 of 100 images\n",
      "Downloading 11 of 100 images\n",
      "Downloading 12 of 100 images\n",
      "Downloading 13 of 100 images\n",
      "Downloading 14 of 100 images\n",
      "Downloading 15 of 100 images\n",
      "Downloading 16 of 100 images\n",
      "Downloading 17 of 100 images\n",
      "Downloading 18 of 100 images\n",
      "Downloading 19 of 100 images\n",
      "Downloading 20 of 100 images\n",
      "Downloading 21 of 100 images\n",
      "Downloading 22 of 100 images\n",
      "Downloading 23 of 100 images\n",
      "Downloading 24 of 100 images\n",
      "Downloading 25 of 100 images\n",
      "Downloading 26 of 100 images\n",
      "Downloading 27 of 100 images\n",
      "Downloading 28 of 100 images\n",
      "Downloading 29 of 100 images\n",
      "Downloading 30 of 100 images\n",
      "Downloading 31 of 100 images\n",
      "Downloading 32 of 100 images\n",
      "Downloading 33 of 100 images\n",
      "Downloading 34 of 100 images\n",
      "Downloading 35 of 100 images\n",
      "Downloading 36 of 100 images\n",
      "Downloading 37 of 100 images\n",
      "Downloading 38 of 100 images\n",
      "Downloading 39 of 100 images\n",
      "Downloading 40 of 100 images\n",
      "Downloading 41 of 100 images\n",
      "Downloading 42 of 100 images\n",
      "Downloading 43 of 100 images\n",
      "Downloading 44 of 100 images\n",
      "Downloading 45 of 100 images\n",
      "Downloading 46 of 100 images\n",
      "Downloading 47 of 100 images\n",
      "Downloading 48 of 100 images\n",
      "Downloading 49 of 100 images\n",
      "Downloading 50 of 100 images\n",
      "Downloading 51 of 100 images\n",
      "Downloading 52 of 100 images\n",
      "Downloading 53 of 100 images\n",
      "Downloading 54 of 100 images\n",
      "Downloading 55 of 100 images\n",
      "Downloading 56 of 100 images\n",
      "Downloading 57 of 100 images\n",
      "Downloading 58 of 100 images\n",
      "Downloading 59 of 100 images\n",
      "Downloading 60 of 100 images\n",
      "Downloading 61 of 100 images\n",
      "Downloading 62 of 100 images\n",
      "Downloading 63 of 100 images\n",
      "Downloading 64 of 100 images\n",
      "Downloading 65 of 100 images\n",
      "Downloading 66 of 100 images\n",
      "Downloading 67 of 100 images\n",
      "Downloading 68 of 100 images\n",
      "Downloading 69 of 100 images\n",
      "Downloading 70 of 100 images\n",
      "Downloading 71 of 100 images\n",
      "Downloading 72 of 100 images\n",
      "Downloading 73 of 100 images\n",
      "Downloading 74 of 100 images\n",
      "Downloading 75 of 100 images\n",
      "Downloading 76 of 100 images\n",
      "Downloading 77 of 100 images\n",
      "Downloading 78 of 100 images\n",
      "Downloading 79 of 100 images\n",
      "Downloading 80 of 100 images\n",
      "Downloading 81 of 100 images\n",
      "Downloading 82 of 100 images\n",
      "Downloading 83 of 100 images\n",
      "Downloading 84 of 100 images\n",
      "Downloading 85 of 100 images\n",
      "Downloading 86 of 100 images\n",
      "Downloading 87 of 100 images\n",
      "Downloading 88 of 100 images\n",
      "Downloading 89 of 100 images\n",
      "Downloading 90 of 100 images\n",
      "Downloading 91 of 100 images\n",
      "Downloading 92 of 100 images\n",
      "Downloading 93 of 100 images\n",
      "Downloading 94 of 100 images\n",
      "Downloading 95 of 100 images\n",
      "Downloading 96 of 100 images\n",
      "Downloading 97 of 100 images\n",
      "Downloading 98 of 100 images\n",
      "Downloading 99 of 100 images\n"
     ]
    }
   ],
   "source": [
    "# Activating the chrome browser ()\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(3)\n",
    "\n",
    "# Opening the google images\n",
    "url = \"https://images.google.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "search_bar = driver.find_element_by_xpath('//*[@id=\"sbtc\"]/div/div[2]/input')    # Finding the search bar using it's xpath\n",
    "search_bar.send_keys(\"cars\")       # Inputing \"fruits\" keyword to search images\n",
    "search_button = driver.find_element_by_xpath('//*[@id=\"sbtc\"]/button')    # Finding the xpath of search button\n",
    "search_button.click()        # Clicking the search button\n",
    "time.sleep(8)\n",
    "# 500 time we scroll down by 10000 in order to generate more images on the website\n",
    "for _ in range(500):\n",
    "    driver.execute_script(\"window.scrollBy(0,12000)\")\n",
    "\n",
    "images = driver.find_elements_by_xpath('//img[@class=\"rg_i Q4LuWd\"]')\n",
    "\n",
    "img_urls = []\n",
    "img_data = []\n",
    "for image in images:\n",
    "    source= image.get_attribute('src')\n",
    "    if source is not None:\n",
    "        if(source[0:4] == 'http'):\n",
    "            img_urls.append(source)\n",
    "            \n",
    "            \n",
    "for i in range(len(img_urls)):\n",
    "    if i >= 100:\n",
    "        break\n",
    "    print(\"Downloading {0} of {1} images\" .format(i, 100))\n",
    "    response= requests.get(img_urls[i])\n",
    "    file = open(r\"C:\\Users\\INPshy\\Desktop\\DATA Science\\Fruits img\\Car\"+str(i)+\".jpg\", \"wb\")\n",
    "    file.write(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 0 of 100 images\n",
      "Downloading 1 of 100 images\n",
      "Downloading 2 of 100 images\n",
      "Downloading 3 of 100 images\n",
      "Downloading 4 of 100 images\n",
      "Downloading 5 of 100 images\n",
      "Downloading 6 of 100 images\n",
      "Downloading 7 of 100 images\n",
      "Downloading 8 of 100 images\n",
      "Downloading 9 of 100 images\n",
      "Downloading 10 of 100 images\n",
      "Downloading 11 of 100 images\n",
      "Downloading 12 of 100 images\n",
      "Downloading 13 of 100 images\n",
      "Downloading 14 of 100 images\n",
      "Downloading 15 of 100 images\n",
      "Downloading 16 of 100 images\n",
      "Downloading 17 of 100 images\n",
      "Downloading 18 of 100 images\n",
      "Downloading 19 of 100 images\n",
      "Downloading 20 of 100 images\n",
      "Downloading 21 of 100 images\n",
      "Downloading 22 of 100 images\n",
      "Downloading 23 of 100 images\n",
      "Downloading 24 of 100 images\n",
      "Downloading 25 of 100 images\n",
      "Downloading 26 of 100 images\n",
      "Downloading 27 of 100 images\n",
      "Downloading 28 of 100 images\n",
      "Downloading 29 of 100 images\n",
      "Downloading 30 of 100 images\n",
      "Downloading 31 of 100 images\n",
      "Downloading 32 of 100 images\n",
      "Downloading 33 of 100 images\n",
      "Downloading 34 of 100 images\n",
      "Downloading 35 of 100 images\n",
      "Downloading 36 of 100 images\n",
      "Downloading 37 of 100 images\n",
      "Downloading 38 of 100 images\n",
      "Downloading 39 of 100 images\n",
      "Downloading 40 of 100 images\n",
      "Downloading 41 of 100 images\n",
      "Downloading 42 of 100 images\n",
      "Downloading 43 of 100 images\n",
      "Downloading 44 of 100 images\n",
      "Downloading 45 of 100 images\n",
      "Downloading 46 of 100 images\n",
      "Downloading 47 of 100 images\n",
      "Downloading 48 of 100 images\n",
      "Downloading 49 of 100 images\n",
      "Downloading 50 of 100 images\n",
      "Downloading 51 of 100 images\n",
      "Downloading 52 of 100 images\n",
      "Downloading 53 of 100 images\n",
      "Downloading 54 of 100 images\n",
      "Downloading 55 of 100 images\n",
      "Downloading 56 of 100 images\n",
      "Downloading 57 of 100 images\n",
      "Downloading 58 of 100 images\n",
      "Downloading 59 of 100 images\n",
      "Downloading 60 of 100 images\n",
      "Downloading 61 of 100 images\n",
      "Downloading 62 of 100 images\n",
      "Downloading 63 of 100 images\n",
      "Downloading 64 of 100 images\n",
      "Downloading 65 of 100 images\n",
      "Downloading 66 of 100 images\n",
      "Downloading 67 of 100 images\n",
      "Downloading 68 of 100 images\n"
     ]
    }
   ],
   "source": [
    "#Activating the chrome browser ()\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(3)\n",
    "\n",
    "# Opening the google images\n",
    "url = \"https://images.google.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "search_bar = driver.find_element_by_xpath('//*[@id=\"sbtc\"]/div/div[2]/input')    # Finding the search bar using it's xpath\n",
    "search_bar.send_keys(\"Machine Learning\")       # Inputing \"fruits\" keyword to search images\n",
    "search_button = driver.find_element_by_xpath('//*[@id=\"sbtc\"]/button')    # Finding the xpath of search button\n",
    "search_button.click()        # Clicking the search button\n",
    "time.sleep(8)\n",
    "# 500 time we scroll down by 10000 in order to generate more images on the website\n",
    "for _ in range(500):\n",
    "    driver.execute_strip(\"window.scrollBy(0,10000)\")\n",
    "\n",
    "images = driver.find_elements_by_xpath('//img[@class=\"rg_i Q4LuWd\"]')\n",
    "\n",
    "img_urls = []\n",
    "img_data = []\n",
    "for image in images:\n",
    "    source= image.get_attribute('src')\n",
    "    if source is not None:\n",
    "        if(source[0:4] == 'http'):\n",
    "            img_urls.append(source)\n",
    "            \n",
    "            \n",
    "for i in range(len(img_urls)):\n",
    "    if i >= 100:\n",
    "        break\n",
    "    print(\"Downloading {0} of {1} images\" .format(i, 100))\n",
    "    response= requests.get(img_urls[i])\n",
    "    file = open(r\"C:\\Users\\INPshy\\Desktop\\DATA Science\\image google\"+str(i)+\".jpg\", \"wb\")\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 5 Geospatial c0ordinates\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\INPshy\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.google.com/maps'\n",
    "driver.get(url)\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element_by_id(\"searchboxinput\")\n",
    "search.send_keys('new delhi')\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "button=driver.find_element_by_xpath('//button[@class=\"searchbox-searchbutton\"]')\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL Extracted:  https://www.google.com/maps/place/New+Delhi,+Delhi/@28.5273522,77.2089851,11z/data=!3m1!4b1!4m5!3m4!1s0x390cfd5b347eb62d:0x52c2b7494e204dce!8m2!3d28.6139391!4d77.2090212\n",
      "Latitude = 28.5273522, Longitude = 77.2089851\n"
     ]
    }
   ],
   "source": [
    " \n",
    "try:\n",
    "    url_string = driver.current_url\n",
    "    print(\"URL Extracted: \", url_string)\n",
    "    lat_lng = re.findall(r'@(.*)data',url_string)\n",
    "    if len(lat_lng):\n",
    "        lat_lng_list = lat_lng[0].split(\",\")\n",
    "        if len(lat_lng_list)>=2:\n",
    "            lat = lat_lng_list[0]\n",
    "            lng = lat_lng_list[1]\n",
    "        print(\"Latitude = {}, Longitude = {}\".format(lat, lng))\n",
    "\n",
    "except Exception as e:\n",
    "        print(\"Error: \", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question no 6 funding trak.in\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\INPshy\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://trak.in/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fund=driver.find_element_by_xpath('//i[@class=\"bf-icon  fa fa-dollar\"]')\n",
    "fund.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01/04/2021',\n",
       " '05/04/2021',\n",
       " '14/04/2021',\n",
       " '07/04/2021',\n",
       " '14/04/2021',\n",
       " '04/03/2021',\n",
       " '31/03/2021',\n",
       " '30/03/2021',\n",
       " '30/03/2021',\n",
       " '23/03/2021',\n",
       " '25/03/2021',\n",
       " '26/03/2021',\n",
       " '11/02/2021',\n",
       " '22/02/2021',\n",
       " '19/02/2021',\n",
       " '17/02/2021',\n",
       " '15/02/2021',\n",
       " '12/02/2021',\n",
       " '12/02/2021',\n",
       " '09/02/2021',\n",
       " '09/02/2021',\n",
       " '15/01/2021',\n",
       " '28/01/2021',\n",
       " '19/01/2021',\n",
       " '19/01/2021',\n",
       " '18/01/2021',\n",
       " '18/01/2021',\n",
       " '11/01/2021',\n",
       " '13/01/2021',\n",
       " '15/12/2020',\n",
       " '21/12/2020',\n",
       " '15/12/2020',\n",
       " '22/12/2020',\n",
       " '15/12/2020',\n",
       " '18/12/2020',\n",
       " '30/11/2020',\n",
       " '30/11/2020',\n",
       " '29/11/2020',\n",
       " '27/11/2020',\n",
       " '25/11/2020',\n",
       " '25/11/2020',\n",
       " '25/11/2020',\n",
       " '24/11/2020',\n",
       " '30/11/2020',\n",
       " '23/11/2020',\n",
       " '28/10/2020',\n",
       " '28/10/2020',\n",
       " '28/10/2020',\n",
       " '27/10/2020',\n",
       " '27/10/2020',\n",
       " '27/10/2020',\n",
       " '27/10/2020',\n",
       " '15/10/2020',\n",
       " '26/10/2020',\n",
       " '28/10/2020',\n",
       " '08/09/2020',\n",
       " '12/09/2020',\n",
       " '09/09/2020',\n",
       " '02/09/2020',\n",
       " '09/09/2020',\n",
       " '07/09/2020',\n",
       " '07/09/2020',\n",
       " '31/08/2020',\n",
       " '31/08/2020',\n",
       " '03/09/2020',\n",
       " '15/08/2020',\n",
       " '13/08/2020',\n",
       " '13/08/2020',\n",
       " '04/08/2020',\n",
       " '11/08/2020',\n",
       " '12/08/2020',\n",
       " '14/08/2020',\n",
       " '10/08/2020',\n",
       " '07/08/2020',\n",
       " '13/08/2020',\n",
       " '15/07/2020',\n",
       " '16/07/2020',\n",
       " '16/07/2020',\n",
       " '14/07/2020',\n",
       " '13/07/2020',\n",
       " '09/07/2020',\n",
       " '10/07/2020',\n",
       " '15/07/2020',\n",
       " '14/07/2020',\n",
       " '13/07/2020',\n",
       " '18/06/2020',\n",
       " '17/06/2020',\n",
       " '17/06/2020',\n",
       " '16/06/2020',\n",
       " '16/06/2020',\n",
       " '15/06/2020',\n",
       " '15/06/2020',\n",
       " '10/06/2020',\n",
       " '11/06/2020',\n",
       " '10/06/2020',\n",
       " '21/05/2020',\n",
       " '20/05/2020',\n",
       " '20/05/2020',\n",
       " '19/05/2020',\n",
       " '19/05/2020',\n",
       " '21/05/2020',\n",
       " '05/05/2020',\n",
       " '11/05/2020',\n",
       " '13/05/2020',\n",
       " '18/05/2020',\n",
       " '09/04/2020',\n",
       " '06/04/2020',\n",
       " '08/04/2020',\n",
       " '07/04/2020',\n",
       " '15/04/2020',\n",
       " '08/04/2020',\n",
       " '31/03/2020',\n",
       " '02/04/2020',\n",
       " '04/03/2020',\n",
       " '02/03/2020',\n",
       " '06/03/2020',\n",
       " '13/03/2020',\n",
       " '12/03/2020',\n",
       " '12/03/2020',\n",
       " '12/03/2020',\n",
       " '12/03/2020',\n",
       " '03/02/2020',\n",
       " '03/02/2020',\n",
       " '31/01/2020',\n",
       " '31/01/2020',\n",
       " '30/01/2020',\n",
       " '03/02/2020',\n",
       " '10/02/2020',\n",
       " '10/02/2020',\n",
       " '18/02/2020',\n",
       " '06/02/2020',\n",
       " '09/01/2020',\n",
       " '13/01/2020',\n",
       " '09/01/2020',\n",
       " '02/01/2020',\n",
       " '02/01/2020',\n",
       " '13/01/2020',\n",
       " '10/01/2020',\n",
       " '12/12/2019',\n",
       " '06/12/2019',\n",
       " '3/12/2019',\n",
       " '13/12/2019',\n",
       " '17/12/2019',\n",
       " '16/12/2019',\n",
       " '16/12/2019',\n",
       " '14/12/2019',\n",
       " '11/12/2019',\n",
       " '20/12/2019',\n",
       " '13/11/2019',\n",
       " '14/11/2019',\n",
       " '13/11/2019',\n",
       " '17/11/2019',\n",
       " '18/11/2019',\n",
       " '15/11/2019',\n",
       " '20/11/2019',\n",
       " '12/11/2019',\n",
       " '20/11/2019',\n",
       " '11/11/2019',\n",
       " '04/10/2019',\n",
       " '02/10/2019',\n",
       " '21/10/2019',\n",
       " '05/09/2019',\n",
       " '04/09/2019',\n",
       " '04/09/2019',\n",
       " '04/09/2019',\n",
       " '04/09/2019',\n",
       " '04/09/2019',\n",
       " '04/09/2019',\n",
       " '04/09/2019',\n",
       " '03/09/2019',\n",
       " '',\n",
       " '01/08/2019',\n",
       " '01/08/2019',\n",
       " '01/08/2019',\n",
       " '01/08/2019',\n",
       " '01/08/2019',\n",
       " '12/08/2019',\n",
       " '13/08/2019',\n",
       " '13/08/2019',\n",
       " '23/08/2019',\n",
       " '23/08/2019',\n",
       " '02/07/2019',\n",
       " '02/07/2019',\n",
       " '01/07/2019',\n",
       " '03/07/2019',\n",
       " '01/07/2019',\n",
       " '04/07/2019',\n",
       " '10/07/2019',\n",
       " '11/07/2019',\n",
       " '10/07/2019',\n",
       " '10/07/2019',\n",
       " '05/06/2019',\n",
       " '04/06/2019',\n",
       " '03/06/2019',\n",
       " '03/06/2019',\n",
       " '04/06/2019',\n",
       " '04/06/2019',\n",
       " '03/06/2019',\n",
       " '06/06/2019',\n",
       " '06/06/2019',\n",
       " '06/06/2019',\n",
       " '06/05/2019',\n",
       " '06/05/2019',\n",
       " '05/05/2019',\n",
       " '01/05/2019',\n",
       " '02/05/2019',\n",
       " '28/05/2019',\n",
       " '28/05/2019',\n",
       " '30/05/2019',\n",
       " '31/05/2019',\n",
       " '16/04/2019',\n",
       " '12/04/2019',\n",
       " '10/04/2019',\n",
       " '13/04/2019',\n",
       " '12/04/2019',\n",
       " '11/04/2019',\n",
       " '10/04/2019',\n",
       " '10/04/2019',\n",
       " '10/04/2019',\n",
       " '11/04/2019',\n",
       " '1/02/2019',\n",
       " '8/02/2019',\n",
       " '13/02/2019',\n",
       " '14/02/2018',\n",
       " '03/01/2019',\n",
       " '04/01/2019',\n",
       " '04/01/2019',\n",
       " '04/12/2018',\n",
       " '01/12/2018',\n",
       " '02/12/2018',\n",
       " '02/12/2018',\n",
       " '04/12/2018',\n",
       " '06/12/2018',\n",
       " '06/12/2018',\n",
       " '01/11/2018',\n",
       " '03/11/2018',\n",
       " '06/11/2018',\n",
       " '08/11/2018',\n",
       " '8/11/2018',\n",
       " '12/11/2018',\n",
       " '12/11/2018',\n",
       " '13/11/2018',\n",
       " '14/11/2018',\n",
       " '19/11/2018',\n",
       " '01/10/2018',\n",
       " '02/10/2018',\n",
       " '04/10/2018',\n",
       " '05/10/2018',\n",
       " '11/10/2018',\n",
       " '12/10/2018',\n",
       " '12/10/2018',\n",
       " '01/09/2018',\n",
       " '03/09/2018',\n",
       " '03/09/2018',\n",
       " '04/09/2018',\n",
       " '04/09/2018',\n",
       " '05/09/2018',\n",
       " '05/09/2018',\n",
       " '06/09/2018',\n",
       " '10/09/2018',\n",
       " '11/09/2018',\n",
       " '01/08/2018',\n",
       " '01/08/2018',\n",
       " '02/08/2018',\n",
       " '03/08/2018',\n",
       " '07/08/2018',\n",
       " '07/08/2018',\n",
       " '07/08/2018',\n",
       " '08/08/2018',\n",
       " '08/08/2018',\n",
       " '08/08/2018',\n",
       " '01/07/2018',\n",
       " '02/07/2018',\n",
       " '04/07/2018',\n",
       " '05/072018',\n",
       " '06/07/2018',\n",
       " '09/07/2018',\n",
       " '09/07/2018',\n",
       " '10/07/2018',\n",
       " '10/07/2018',\n",
       " '10/07/2018',\n",
       " '01/10/2018',\n",
       " '02/10/2018',\n",
       " '04/10/2018',\n",
       " '05/10/2018',\n",
       " '11/10/2018',\n",
       " '12/10/2018',\n",
       " '12/10/2018',\n",
       " '01/09/2018',\n",
       " '03/09/2018',\n",
       " '03/09/2018',\n",
       " '04/09/2018',\n",
       " '04/09/2018',\n",
       " '05/09/2018',\n",
       " '05/09/2018',\n",
       " '06/09/2018',\n",
       " '10/09/2018',\n",
       " '11/09/2018',\n",
       " '01/08/2018',\n",
       " '01/08/2018',\n",
       " '02/08/2018',\n",
       " '03/08/2018',\n",
       " '07/08/2018',\n",
       " '07/08/2018',\n",
       " '07/08/2018',\n",
       " '08/08/2018',\n",
       " '08/08/2018',\n",
       " '08/08/2018',\n",
       " '01/07/2018',\n",
       " '02/07/2018',\n",
       " '04/07/2018',\n",
       " '05/072018',\n",
       " '06/07/2018',\n",
       " '09/07/2018',\n",
       " '09/07/2018',\n",
       " '10/07/2018',\n",
       " '10/07/2018',\n",
       " '10/07/2018',\n",
       " '01/10/2018',\n",
       " '02/10/2018',\n",
       " '04/10/2018',\n",
       " '05/10/2018',\n",
       " '11/10/2018',\n",
       " '12/10/2018',\n",
       " '12/10/2018',\n",
       " '01/09/2018',\n",
       " '03/09/2018',\n",
       " '03/09/2018',\n",
       " '04/09/2018',\n",
       " '04/09/2018',\n",
       " '05/09/2018',\n",
       " '05/09/2018',\n",
       " '06/09/2018',\n",
       " '10/09/2018',\n",
       " '11/09/2018',\n",
       " '01/08/2018',\n",
       " '01/08/2018',\n",
       " '02/08/2018',\n",
       " '03/08/2018',\n",
       " '07/08/2018',\n",
       " '07/08/2018',\n",
       " '07/08/2018',\n",
       " '08/08/2018',\n",
       " '08/08/2018',\n",
       " '08/08/2018',\n",
       " '01/07/2018',\n",
       " '02/07/2018',\n",
       " '04/07/2018',\n",
       " '05/072018',\n",
       " '06/07/2018',\n",
       " '09/07/2018',\n",
       " '09/07/2018',\n",
       " '10/07/2018',\n",
       " '10/07/2018',\n",
       " '10/07/2018',\n",
       " '01/10/2018',\n",
       " '02/10/2018',\n",
       " '04/10/2018',\n",
       " '05/10/2018',\n",
       " '11/10/2018',\n",
       " '12/10/2018',\n",
       " '12/10/2018',\n",
       " '01/09/2018',\n",
       " '03/09/2018',\n",
       " '03/09/2018',\n",
       " '04/09/2018',\n",
       " '04/09/2018',\n",
       " '05/09/2018',\n",
       " '05/09/2018',\n",
       " '06/09/2018',\n",
       " '10/09/2018',\n",
       " '11/09/2018',\n",
       " '01/08/2018',\n",
       " '01/08/2018',\n",
       " '02/08/2018',\n",
       " '03/08/2018',\n",
       " '07/08/2018',\n",
       " '07/08/2018',\n",
       " '07/08/2018',\n",
       " '08/08/2018',\n",
       " '08/08/2018',\n",
       " '08/08/2018',\n",
       " '01/07/2018',\n",
       " '02/07/2018',\n",
       " '04/07/2018',\n",
       " '05/072018',\n",
       " '06/07/2018',\n",
       " '09/07/2018',\n",
       " '09/07/2018',\n",
       " '10/07/2018',\n",
       " '10/07/2018',\n",
       " '10/07/2018']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fetch date\n",
    "Date=[]\n",
    "try:\n",
    "    date=driver.find_elements_by_xpath('//td[@class=\"column-2\"]')\n",
    "    for i in date:\n",
    "        Date.append(i.text)\n",
    "except NoSuchElementException:\n",
    "        Date.append('-')\n",
    "Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Date.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BYJU’S',\n",
       " 'Meesho',\n",
       " 'Swiggy',\n",
       " 'Groww',\n",
       " 'Beldara',\n",
       " 'DealShare',\n",
       " 'Uniphore',\n",
       " 'Dunzo',\n",
       " 'BYJU’S',\n",
       " 'SkilloVilla',\n",
       " 'CityMall',\n",
       " 'DotPe',\n",
       " 'Doubtnut',\n",
       " 'Zomato',\n",
       " 'Fingerlix',\n",
       " 'Zolve',\n",
       " 'KreditBee',\n",
       " 'Pepperfry',\n",
       " 'Grofers',\n",
       " 'Nothing',\n",
       " 'SplashLearn',\n",
       " 'Digit Insurance',\n",
       " 'Bombay Shaving Company',\n",
       " 'DeHaat',\n",
       " 'Darwinbox',\n",
       " 'mfine',\n",
       " 'Udayy',\n",
       " 'True Elements',\n",
       " 'Saveo',\n",
       " 'Bira 91',\n",
       " 'Pine Labs',\n",
       " 'Zenoti',\n",
       " 'Tax Buddy India',\n",
       " 'Delhivery',\n",
       " 'PagarBook',\n",
       " 'Codingal',\n",
       " 'CRED',\n",
       " 'Bira 91',\n",
       " 'Chumbak',\n",
       " 'Cityflo',\n",
       " 'Shipsy',\n",
       " 'Unacademy',\n",
       " 'Cashfree',\n",
       " 'Credgenics',\n",
       " 'Country Delight',\n",
       " 'Nykaa',\n",
       " 'Betterplace',\n",
       " 'FlexiLoans',\n",
       " 'GetVantage',\n",
       " 'FreshToHome',\n",
       " 'Origo',\n",
       " 'Origo',\n",
       " 'Treebo Hotels',\n",
       " 'Hubilo',\n",
       " 'CredAble',\n",
       " 'Byju’s',\n",
       " 'mCaffeine',\n",
       " 'Qshala',\n",
       " 'Winzo',\n",
       " 'Hippo Video',\n",
       " 'Melorra',\n",
       " '1mg',\n",
       " 'mfine',\n",
       " 'Apna',\n",
       " 'Railofy',\n",
       " 'Practo',\n",
       " 'Medlife',\n",
       " 'HungerBox',\n",
       " 'Dunzo',\n",
       " 'Terra.do',\n",
       " 'Classplus',\n",
       " 'Niyo',\n",
       " 'ZestMoney',\n",
       " 'FreshToHome',\n",
       " 'Eduvanz',\n",
       " 'Flipkart',\n",
       " 'Vedantu',\n",
       " 'Crio',\n",
       " 'goDutch',\n",
       " 'Mystifly',\n",
       " 'JetSynthesys',\n",
       " 'gigIndia',\n",
       " 'PumPumPum',\n",
       " 'FLYX',\n",
       " 'Open Appliances Pvt. Ltd.',\n",
       " 'Drishti Technologies',\n",
       " 'Stellaps',\n",
       " 'Peppermint',\n",
       " 'Jai Kisan',\n",
       " 'Biomoneta',\n",
       " 'Sai Estate Management and Skills Institute',\n",
       " 'LetsTransport',\n",
       " 'WayCool Foods',\n",
       " 'Myelin Foundry',\n",
       " 'Hapramp',\n",
       " 'leap.club',\n",
       " 'Tring',\n",
       " 'Khatabook',\n",
       " 'Vakilsearch',\n",
       " 'Lendingkart',\n",
       " 'No Worry No Tension Healthcare (NWNT)',\n",
       " 'Classplus',\n",
       " 'Nykaa',\n",
       " 'Magicpin',\n",
       " 'LetsTransport',\n",
       " 'Vedantu',\n",
       " 'Swiggy',\n",
       " 'Zupee',\n",
       " 'DeHaat',\n",
       " 'BigBasket',\n",
       " 'Fingerlix',\n",
       " 'Nykaa',\n",
       " 'Recko',\n",
       " 'Soxytoes',\n",
       " 'Chqbook.com',\n",
       " 'Paperboat',\n",
       " 'CollegeKhabri',\n",
       " 'FamPay',\n",
       " 'MultiLiving',\n",
       " 'Ola Electric',\n",
       " 'Mera Kisan',\n",
       " '1mg',\n",
       " 'RACEnergy',\n",
       " 'Adonmo',\n",
       " 'DoubtNut',\n",
       " 'MultiplyMyLeads',\n",
       " 'Embibe',\n",
       " 'FirstCry',\n",
       " 'Pepperfry',\n",
       " 'MaxWholesale',\n",
       " 'Dot',\n",
       " 'BYJU’S',\n",
       " 'Shuttl',\n",
       " 'Mamaearth',\n",
       " 'https://www.wealthbucket.in/',\n",
       " 'Fashor',\n",
       " 'Pando',\n",
       " 'Zomato',\n",
       " 'Ecozen',\n",
       " 'CarDekho',\n",
       " 'Dhruva Space',\n",
       " 'Rivigo',\n",
       " 'Healthians',\n",
       " 'Licious',\n",
       " 'InCred',\n",
       " 'Trell',\n",
       " 'Rein Games',\n",
       " 'Lenskart.com',\n",
       " 'Freshworks',\n",
       " 'Misters',\n",
       " 'Sunstone Eduversity Pvt. Ltd',\n",
       " 'Burger Singh',\n",
       " 'Healthians',\n",
       " 'Ninjacart',\n",
       " 'Aye Finance',\n",
       " 'SuperGaming',\n",
       " 'Clumio',\n",
       " 'eBikeGo',\n",
       " 'Dunzo',\n",
       " 'Udaan',\n",
       " 'The Man Company',\n",
       " 'FPL Technologies',\n",
       " 'Cashflo',\n",
       " 'Digital F5',\n",
       " '3rdFlix',\n",
       " '75F',\n",
       " 'Myelin Foundry',\n",
       " 'Atomberg Technology',\n",
       " 'GOQii',\n",
       " 'Vyapar App',\n",
       " '',\n",
       " 'CarDekho',\n",
       " 'Progcap',\n",
       " 'MyPetrolPump',\n",
       " 'Alteria Capital',\n",
       " 'Pine Labs',\n",
       " 'Meesho',\n",
       " 'Cars24',\n",
       " 'Uniphore',\n",
       " 'Zendrive',\n",
       " 'Lo! Foods',\n",
       " 'RenewBuy',\n",
       " 'Atlan',\n",
       " 'WizCounsel',\n",
       " 'Ola Cabs',\n",
       " 'Uniphore',\n",
       " 'Daalchini Technologies',\n",
       " \"BYJU'S\",\n",
       " 'Moglix',\n",
       " 'Ezyhaul',\n",
       " 'Indus OS',\n",
       " 'NoBroker',\n",
       " 'Bira91',\n",
       " 'FabHotels',\n",
       " 'Avail Finance',\n",
       " 'BharatPe',\n",
       " 'Recykal',\n",
       " 'Agara Labs',\n",
       " 'Sistema.bio',\n",
       " 'Chakr Innovation',\n",
       " 'Pratilipi',\n",
       " 'Ola Electric',\n",
       " 'Saahas Zero Waste',\n",
       " 'StyleDotMe',\n",
       " 'BlackBuck',\n",
       " 'Zenoti',\n",
       " 'Ather Energy',\n",
       " 'FreshVnF',\n",
       " 'GlowRoad',\n",
       " 'Bira91',\n",
       " 'Kuvera',\n",
       " 'Medlife',\n",
       " 'Kabadiwala',\n",
       " 'Tripoto',\n",
       " 'Azah',\n",
       " 'Setu',\n",
       " 'Toppr',\n",
       " 'Craftsvilla',\n",
       " 'Unacademy',\n",
       " 'CleverTap',\n",
       " 'FleetX',\n",
       " 'Zilingo',\n",
       " 'NanoClean Global',\n",
       " 'OyoRooms',\n",
       " 'CarDekho',\n",
       " 'Vyome Therapeutics Inc.',\n",
       " 'Samunnati Financial Intermediation & Services Pvt. Ltd',\n",
       " 'Manch',\n",
       " 'UrbanClap Technologies Pvt. Ltd',\n",
       " 'Guiddoo',\n",
       " 'Career Anna',\n",
       " 'Nagpur Wholesale',\n",
       " 'ShopKirana',\n",
       " 'BuildSupply',\n",
       " 'GoDesi',\n",
       " 'Veritas Finance Ltd.',\n",
       " 'Meesho',\n",
       " 'Mobile Premier League',\n",
       " 'A&R Bon Vivants',\n",
       " 'Blackbuck',\n",
       " 'MilkBAsket',\n",
       " 'DriveU',\n",
       " 'CleanseCar',\n",
       " 'Automation Anywhere',\n",
       " 'Northmist',\n",
       " 'Origo Commodities India Pvt. Ltd',\n",
       " 'Grover Zampa',\n",
       " 'Droom',\n",
       " 'Innov8',\n",
       " 'Blackbuck',\n",
       " 'LetsTransport',\n",
       " 'Netmeds',\n",
       " 'Udaan',\n",
       " 'Daily hunt',\n",
       " '3HCare',\n",
       " 'HappyGoEasy',\n",
       " 'Nykaa',\n",
       " 'Mad Street Den',\n",
       " 'Dream11',\n",
       " 'MamaEarth',\n",
       " 'AutoGrid',\n",
       " 'dishq',\n",
       " 'HealthFin',\n",
       " 'Samosa Labs',\n",
       " 'ZiffyHomes',\n",
       " 'My OmNamo',\n",
       " 'ShopX',\n",
       " 'MakeMyTrip',\n",
       " 'Hansel io',\n",
       " 'Metro Bikes',\n",
       " 'Phone Pe',\n",
       " 'Leena AI',\n",
       " 'Biryani By Kilo',\n",
       " 'Anchanto',\n",
       " 'Loan Tap',\n",
       " 'PolicyBazaar',\n",
       " 'zippserv',\n",
       " 'Groww',\n",
       " 'Avenue Growth',\n",
       " 'iNICU',\n",
       " 'Kinara Capital',\n",
       " 'Northmist',\n",
       " 'Origo Commodities India Pvt. Ltd',\n",
       " 'Grover Zampa',\n",
       " 'Droom',\n",
       " 'Innov8',\n",
       " 'Blackbuck',\n",
       " 'LetsTransport',\n",
       " 'Netmeds',\n",
       " 'Udaan',\n",
       " 'Daily hunt',\n",
       " '3HCare',\n",
       " 'HappyGoEasy',\n",
       " 'Nykaa',\n",
       " 'Mad Street Den',\n",
       " 'Dream11',\n",
       " 'MamaEarth',\n",
       " 'AutoGrid',\n",
       " 'dishq',\n",
       " 'HealthFin',\n",
       " 'Samosa Labs',\n",
       " 'ZiffyHomes',\n",
       " 'My OmNamo',\n",
       " 'ShopX',\n",
       " 'MakeMyTrip',\n",
       " 'Hansel io',\n",
       " 'Metro Bikes',\n",
       " 'Phone Pe',\n",
       " 'Leena AI',\n",
       " 'Biryani By Kilo',\n",
       " 'Anchanto',\n",
       " 'Loan Tap',\n",
       " 'PolicyBazaar',\n",
       " 'zippserv',\n",
       " 'Groww',\n",
       " 'Avenue Growth',\n",
       " 'iNICU',\n",
       " 'Kinara Capital',\n",
       " 'Northmist',\n",
       " 'Origo Commodities India Pvt. Ltd',\n",
       " 'Grover Zampa',\n",
       " 'Droom',\n",
       " 'Innov8',\n",
       " 'Blackbuck',\n",
       " 'LetsTransport',\n",
       " 'Netmeds',\n",
       " 'Udaan',\n",
       " 'Daily hunt',\n",
       " '3HCare',\n",
       " 'HappyGoEasy',\n",
       " 'Nykaa',\n",
       " 'Mad Street Den',\n",
       " 'Dream11',\n",
       " 'MamaEarth',\n",
       " 'AutoGrid',\n",
       " 'dishq',\n",
       " 'HealthFin',\n",
       " 'Samosa Labs',\n",
       " 'ZiffyHomes',\n",
       " 'My OmNamo',\n",
       " 'ShopX',\n",
       " 'MakeMyTrip',\n",
       " 'Hansel io',\n",
       " 'Metro Bikes',\n",
       " 'Phone Pe',\n",
       " 'Leena AI',\n",
       " 'Biryani By Kilo',\n",
       " 'Anchanto',\n",
       " 'Loan Tap',\n",
       " 'PolicyBazaar',\n",
       " 'zippserv',\n",
       " 'Groww',\n",
       " 'Avenue Growth',\n",
       " 'iNICU',\n",
       " 'Kinara Capital',\n",
       " 'Northmist',\n",
       " 'Origo Commodities India Pvt. Ltd',\n",
       " 'Grover Zampa',\n",
       " 'Droom',\n",
       " 'Innov8',\n",
       " 'Blackbuck',\n",
       " 'LetsTransport',\n",
       " 'Netmeds',\n",
       " 'Udaan',\n",
       " 'Daily hunt',\n",
       " '3HCare',\n",
       " 'HappyGoEasy',\n",
       " 'Nykaa',\n",
       " 'Mad Street Den',\n",
       " 'Dream11',\n",
       " 'MamaEarth',\n",
       " 'AutoGrid',\n",
       " 'dishq',\n",
       " 'HealthFin',\n",
       " 'Samosa Labs',\n",
       " 'ZiffyHomes',\n",
       " 'My OmNamo',\n",
       " 'ShopX',\n",
       " 'MakeMyTrip',\n",
       " 'Hansel io',\n",
       " 'Metro Bikes',\n",
       " 'Phone Pe',\n",
       " 'Leena AI',\n",
       " 'Biryani By Kilo',\n",
       " 'Anchanto',\n",
       " 'Loan Tap',\n",
       " 'PolicyBazaar',\n",
       " 'zippserv',\n",
       " 'Groww',\n",
       " 'Avenue Growth',\n",
       " 'iNICU',\n",
       " 'Kinara Capital']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fetch Startup name\n",
    "Startup=[]\n",
    "try:\n",
    "    startup=driver.find_elements_by_xpath('//td[@class=\"column-3\"]')\n",
    "    for i in startup:\n",
    "        Startup.append(i.text)\n",
    "except NoSuchElementException:\n",
    "        Startup.append('-')\n",
    "Startup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch Industry Vertical\n",
    "Industry_vertical=[]\n",
    "\n",
    "try:\n",
    "    industry=driver.find_elements_by_xpath('//td[@class=\"column-4\"]')\n",
    "    for i in industry:\n",
    "        Industry_vertical.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Industry_vertical.append('-')\n",
    "Industry_vertical\n",
    "#fetch Subvertical \n",
    "Sub_vertical=[]\n",
    "try:\n",
    "    sub=driver.find_elements_by_xpath('//td[@class=\"column-5\"]')\n",
    "    for j in sub:\n",
    "        Sub_vertical.append(j.text)\n",
    "except NoSuchElementException:\n",
    "    Sub_vertical.append('-')\n",
    "#fetch city\n",
    "City=[]\n",
    "try:\n",
    "    city=driver.find_elements_by_xpath('//td[@class=\"column-6\"]')\n",
    "    for k in city:\n",
    "        City.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    City.append('-')\n",
    "#fetch Investor name;\n",
    "Investor=[]\n",
    "try:\n",
    "    investor=driver.find_elements_by_xpath('//td[@class=\"column-7\"]')\n",
    "    for l in investor:\n",
    "        Investor.append(l.text)\n",
    "except NoSuchElementException:\n",
    "    Investor.append('-')\n",
    "#fetch Investment type\n",
    "Investment_type=[]\n",
    "try:\n",
    "    invest_type=driver.find_elements_by_xpath('//td[@class=\"column-8\"]')\n",
    "    for m in invest_type:\n",
    "        Investment_type.append(m.text)\n",
    "except NoSuchElementException:\n",
    "    Investment_type.append('-')\n",
    "    \n",
    "#fetch fund \n",
    "Fund=[]\n",
    "try:\n",
    "    fund=driver.find_elements_by_xpath('//td[@class=\"column-9\"]')\n",
    "    for n in fund:\n",
    "        Fund.append(n.text)\n",
    "except NoSuchElementException:\n",
    "    Fund.append('-')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select data from 55 rows to 85 rows for (sept to july second quarter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Startup</th>\n",
       "      <th>Industry Vertical</th>\n",
       "      <th>Sub Vertical</th>\n",
       "      <th>City</th>\n",
       "      <th>Investor Name</th>\n",
       "      <th>Investment type</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08/09/2020</td>\n",
       "      <td>Byju’s</td>\n",
       "      <td>EduTech</td>\n",
       "      <td>Online Tutoring</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Silver Lake, Tiger Global, General Atlantic an...</td>\n",
       "      <td>Private Equity</td>\n",
       "      <td>500,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12/09/2020</td>\n",
       "      <td>mCaffeine</td>\n",
       "      <td>Personal Care</td>\n",
       "      <td>Skincare &amp; Haircare</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Amicus Capital Private Equity I LLP, Amicus Ca...</td>\n",
       "      <td>Series B</td>\n",
       "      <td>3,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>09/09/2020</td>\n",
       "      <td>Qshala</td>\n",
       "      <td>EduTech</td>\n",
       "      <td>Online Curiosity Platform for Kids</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Rainmatter Capital</td>\n",
       "      <td>Angel</td>\n",
       "      <td>370,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02/09/2020</td>\n",
       "      <td>Winzo</td>\n",
       "      <td>Online Gaming</td>\n",
       "      <td>Online Gaming</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Kalaari Capital Partners, IndigoEdge Managemen...</td>\n",
       "      <td>Series B</td>\n",
       "      <td>15,500,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>09/09/2020</td>\n",
       "      <td>Hippo Video</td>\n",
       "      <td>Video Customer Experience(CX) Platform</td>\n",
       "      <td>Video Customer Experience(CX) Platform</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Alpha Wave Incubation, Exfinity Venture Partne...</td>\n",
       "      <td>Series A</td>\n",
       "      <td>4,500,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>07/09/2020</td>\n",
       "      <td>Melorra</td>\n",
       "      <td>E-commerce</td>\n",
       "      <td>Online Jewelry Store</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Shadow Holdings, Lightbox.</td>\n",
       "      <td>Debt Financing</td>\n",
       "      <td>upto 8,900,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>07/09/2020</td>\n",
       "      <td>1mg</td>\n",
       "      <td>E-commerce</td>\n",
       "      <td>Online Pharmacy</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Gaja Capital, Tata Capital, Partners Group</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>100,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>31/08/2020</td>\n",
       "      <td>mfine</td>\n",
       "      <td>HealthTech</td>\n",
       "      <td>On-Demand Healthcare Services</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Caretech Pte Inc</td>\n",
       "      <td>Series B</td>\n",
       "      <td>5,400,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>31/08/2020</td>\n",
       "      <td>Apna</td>\n",
       "      <td>Human Resources</td>\n",
       "      <td>Recruitment Platform</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Lightspeed India and Sequoia Capital India</td>\n",
       "      <td>Series A</td>\n",
       "      <td>8,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>03/09/2020</td>\n",
       "      <td>Railofy</td>\n",
       "      <td>Transportation</td>\n",
       "      <td>WL &amp; RAC protection platform</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Chiratae Ventures</td>\n",
       "      <td>Seed</td>\n",
       "      <td>950,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15/08/2020</td>\n",
       "      <td>Practo</td>\n",
       "      <td>HealthTech</td>\n",
       "      <td>Health care and Wellness</td>\n",
       "      <td>Finance</td>\n",
       "      <td>A1A Company</td>\n",
       "      <td>Series F</td>\n",
       "      <td>32,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13/08/2020</td>\n",
       "      <td>Medlife</td>\n",
       "      <td>E-commerce</td>\n",
       "      <td>Online Pharmacy</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Prasid Uno Family Trust and SC Credit Fund</td>\n",
       "      <td></td>\n",
       "      <td>23,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13/08/2020</td>\n",
       "      <td>HungerBox</td>\n",
       "      <td>FoodTech</td>\n",
       "      <td>Online Food Delivery Service</td>\n",
       "      <td>Finance</td>\n",
       "      <td>One97, Sabre Partners Trust, Pratithi Investme...</td>\n",
       "      <td>Series D1</td>\n",
       "      <td>1,560,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>04/08/2020</td>\n",
       "      <td>Dunzo</td>\n",
       "      <td>Hyper-local Logistics</td>\n",
       "      <td>Online Delivery Services</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Existing Backers</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>30,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11/08/2020</td>\n",
       "      <td>Terra.do</td>\n",
       "      <td>EduTech</td>\n",
       "      <td>Online Climate School, E-learning</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Stanford Angels and Entrepreneurs (India), BEE...</td>\n",
       "      <td>Seed</td>\n",
       "      <td>1,400,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12/08/2020</td>\n",
       "      <td>Classplus</td>\n",
       "      <td>EduTech</td>\n",
       "      <td>E-learning, Online Tutoring</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Falcon Edge</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>upto 15,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>14/08/2020</td>\n",
       "      <td>Niyo</td>\n",
       "      <td>FinTech</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Niyo Solutions Inc.</td>\n",
       "      <td></td>\n",
       "      <td>6,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10/08/2020</td>\n",
       "      <td>ZestMoney</td>\n",
       "      <td>FinTech</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Primrose Hills Ventures</td>\n",
       "      <td></td>\n",
       "      <td>10,670,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>07/08/2020</td>\n",
       "      <td>FreshToHome</td>\n",
       "      <td>E-commerce</td>\n",
       "      <td>Food Delivery</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Ascent Capital</td>\n",
       "      <td>Venture</td>\n",
       "      <td>16,200,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>13/08/2020</td>\n",
       "      <td>Eduvanz</td>\n",
       "      <td>FinTech</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Sequoia India, Unitus</td>\n",
       "      <td>Series A</td>\n",
       "      <td>5,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>15/07/2020</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>E-commerce</td>\n",
       "      <td>E-commerce</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Walmart Inc</td>\n",
       "      <td>M&amp;A</td>\n",
       "      <td>1,200,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>16/07/2020</td>\n",
       "      <td>Vedantu</td>\n",
       "      <td>EduTech</td>\n",
       "      <td>Online Tutoring</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Coatue Management</td>\n",
       "      <td>Series D</td>\n",
       "      <td>100,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>16/07/2020</td>\n",
       "      <td>Crio</td>\n",
       "      <td>EduTech</td>\n",
       "      <td>Learning Platform for Developers</td>\n",
       "      <td>Finance</td>\n",
       "      <td>021 Capital</td>\n",
       "      <td>pre-Series A</td>\n",
       "      <td>934,160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>14/07/2020</td>\n",
       "      <td>goDutch</td>\n",
       "      <td>FinTech</td>\n",
       "      <td>Group Payments</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Matrix India,Y Combinator, Global Founders Cap...</td>\n",
       "      <td>Seed</td>\n",
       "      <td>1,700,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>13/07/2020</td>\n",
       "      <td>Mystifly</td>\n",
       "      <td>Airfare Marketplace</td>\n",
       "      <td>Ticketing, Airline Retailing, and Post-Ticketi...</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Recruit Co. Ltd.</td>\n",
       "      <td>pre-Series B</td>\n",
       "      <td>3,300,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>JetSynthesys</td>\n",
       "      <td>Gaming and Entertainment</td>\n",
       "      <td>Gaming and Entertainment</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Adar Poonawalla and Kris Gopalakrishnan.</td>\n",
       "      <td>Venture-Series Unknown</td>\n",
       "      <td>400,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>10/07/2020</td>\n",
       "      <td>gigIndia</td>\n",
       "      <td>Marketplace</td>\n",
       "      <td>Crowd Sourcing, Freelance</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Incubate Fund India and Beyond Next Ventures</td>\n",
       "      <td>pre-Series A</td>\n",
       "      <td>974,200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>15/07/2020</td>\n",
       "      <td>PumPumPum</td>\n",
       "      <td>Automotive Rental</td>\n",
       "      <td>Used Car-leasing platform</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Early Adapters Syndicate</td>\n",
       "      <td>Seed</td>\n",
       "      <td>292,800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>14/07/2020</td>\n",
       "      <td>FLYX</td>\n",
       "      <td>OTT Player</td>\n",
       "      <td>Streaming Social Network</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Raj Mishra, founder of AIT Global Inc</td>\n",
       "      <td>pre-Seed</td>\n",
       "      <td>200,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>13/07/2020</td>\n",
       "      <td>Open Appliances Pvt. Ltd.</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Internet-of-Things Security Solutions</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Unicorn India Ventures</td>\n",
       "      <td>Venture-Series Unknown</td>\n",
       "      <td>500,000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date                    Startup  \\\n",
       "0   08/09/2020                     Byju’s   \n",
       "1   12/09/2020                  mCaffeine   \n",
       "2   09/09/2020                     Qshala   \n",
       "3   02/09/2020                      Winzo   \n",
       "4   09/09/2020                Hippo Video   \n",
       "5   07/09/2020                    Melorra   \n",
       "6   07/09/2020                        1mg   \n",
       "7   31/08/2020                      mfine   \n",
       "8   31/08/2020                       Apna   \n",
       "9   03/09/2020                    Railofy   \n",
       "10  15/08/2020                     Practo   \n",
       "11  13/08/2020                    Medlife   \n",
       "12  13/08/2020                  HungerBox   \n",
       "13  04/08/2020                      Dunzo   \n",
       "14  11/08/2020                   Terra.do   \n",
       "15  12/08/2020                  Classplus   \n",
       "16  14/08/2020                       Niyo   \n",
       "17  10/08/2020                  ZestMoney   \n",
       "18  07/08/2020                FreshToHome   \n",
       "19  13/08/2020                    Eduvanz   \n",
       "20  15/07/2020                   Flipkart   \n",
       "21  16/07/2020                    Vedantu   \n",
       "22  16/07/2020                       Crio   \n",
       "23  14/07/2020                    goDutch   \n",
       "24  13/07/2020                   Mystifly   \n",
       "25  09/07/2020               JetSynthesys   \n",
       "26  10/07/2020                   gigIndia   \n",
       "27  15/07/2020                  PumPumPum   \n",
       "28  14/07/2020                       FLYX   \n",
       "29  13/07/2020  Open Appliances Pvt. Ltd.   \n",
       "\n",
       "                         Industry Vertical  \\\n",
       "0                                  EduTech   \n",
       "1                            Personal Care   \n",
       "2                                  EduTech   \n",
       "3                            Online Gaming   \n",
       "4   Video Customer Experience(CX) Platform   \n",
       "5                               E-commerce   \n",
       "6                               E-commerce   \n",
       "7                               HealthTech   \n",
       "8                          Human Resources   \n",
       "9                           Transportation   \n",
       "10                              HealthTech   \n",
       "11                              E-commerce   \n",
       "12                                FoodTech   \n",
       "13                   Hyper-local Logistics   \n",
       "14                                 EduTech   \n",
       "15                                 EduTech   \n",
       "16                                 FinTech   \n",
       "17                                 FinTech   \n",
       "18                              E-commerce   \n",
       "19                                 FinTech   \n",
       "20                              E-commerce   \n",
       "21                                 EduTech   \n",
       "22                                 EduTech   \n",
       "23                                 FinTech   \n",
       "24                     Airfare Marketplace   \n",
       "25                Gaming and Entertainment   \n",
       "26                             Marketplace   \n",
       "27                       Automotive Rental   \n",
       "28                              OTT Player   \n",
       "29                  Information Technology   \n",
       "\n",
       "                                         Sub Vertical     City  \\\n",
       "0                                     Online Tutoring  Finance   \n",
       "1                                 Skincare & Haircare  Finance   \n",
       "2                  Online Curiosity Platform for Kids  Finance   \n",
       "3                                       Online Gaming  Finance   \n",
       "4              Video Customer Experience(CX) Platform  Finance   \n",
       "5                                Online Jewelry Store  Finance   \n",
       "6                                     Online Pharmacy  Finance   \n",
       "7                       On-Demand Healthcare Services  Finance   \n",
       "8                                Recruitment Platform  Finance   \n",
       "9                        WL & RAC protection platform  Finance   \n",
       "10                           Health care and Wellness  Finance   \n",
       "11                                    Online Pharmacy  Finance   \n",
       "12                       Online Food Delivery Service  Finance   \n",
       "13                           Online Delivery Services  Finance   \n",
       "14                  Online Climate School, E-learning  Finance   \n",
       "15                        E-learning, Online Tutoring  Finance   \n",
       "16                                 Financial Services  Finance   \n",
       "17                                 Financial Services  Finance   \n",
       "18                                      Food Delivery  Finance   \n",
       "19                                 Financial Services  Finance   \n",
       "20                                         E-commerce  Finance   \n",
       "21                                    Online Tutoring  Finance   \n",
       "22                   Learning Platform for Developers  Finance   \n",
       "23                                     Group Payments  Finance   \n",
       "24  Ticketing, Airline Retailing, and Post-Ticketi...  Finance   \n",
       "25                           Gaming and Entertainment  Finance   \n",
       "26                          Crowd Sourcing, Freelance  Finance   \n",
       "27                          Used Car-leasing platform  Finance   \n",
       "28                           Streaming Social Network  Finance   \n",
       "29              Internet-of-Things Security Solutions  Finance   \n",
       "\n",
       "                                        Investor Name         Investment type  \\\n",
       "0   Silver Lake, Tiger Global, General Atlantic an...          Private Equity   \n",
       "1   Amicus Capital Private Equity I LLP, Amicus Ca...                Series B   \n",
       "2                                  Rainmatter Capital                   Angel   \n",
       "3   Kalaari Capital Partners, IndigoEdge Managemen...                Series B   \n",
       "4   Alpha Wave Incubation, Exfinity Venture Partne...                Series A   \n",
       "5                          Shadow Holdings, Lightbox.          Debt Financing   \n",
       "6          Gaja Capital, Tata Capital, Partners Group             In Progress   \n",
       "7                                    Caretech Pte Inc                Series B   \n",
       "8          Lightspeed India and Sequoia Capital India                Series A   \n",
       "9                                   Chiratae Ventures                    Seed   \n",
       "10                                        A1A Company                Series F   \n",
       "11         Prasid Uno Family Trust and SC Credit Fund                           \n",
       "12  One97, Sabre Partners Trust, Pratithi Investme...               Series D1   \n",
       "13                                   Existing Backers             In Progress   \n",
       "14  Stanford Angels and Entrepreneurs (India), BEE...                    Seed   \n",
       "15                                        Falcon Edge             In Progress   \n",
       "16                                Niyo Solutions Inc.                           \n",
       "17                            Primrose Hills Ventures                           \n",
       "18                                     Ascent Capital                 Venture   \n",
       "19                              Sequoia India, Unitus                Series A   \n",
       "20                                        Walmart Inc                     M&A   \n",
       "21                                  Coatue Management                Series D   \n",
       "22                                        021 Capital            pre-Series A   \n",
       "23  Matrix India,Y Combinator, Global Founders Cap...                    Seed   \n",
       "24                                   Recruit Co. Ltd.            pre-Series B   \n",
       "25           Adar Poonawalla and Kris Gopalakrishnan.  Venture-Series Unknown   \n",
       "26       Incubate Fund India and Beyond Next Ventures            pre-Series A   \n",
       "27                           Early Adapters Syndicate                    Seed   \n",
       "28              Raj Mishra, founder of AIT Global Inc                pre-Seed   \n",
       "29                             Unicorn India Ventures  Venture-Series Unknown   \n",
       "\n",
       "             Amount  \n",
       "0       500,000,000  \n",
       "1         3,000,000  \n",
       "2           370,000  \n",
       "3        15,500,000  \n",
       "4         4,500,000  \n",
       "5    upto 8,900,000  \n",
       "6       100,000,000  \n",
       "7         5,400,000  \n",
       "8         8,000,000  \n",
       "9           950,000  \n",
       "10       32,000,000  \n",
       "11       23,000,000  \n",
       "12        1,560,000  \n",
       "13       30,000,000  \n",
       "14        1,400,000  \n",
       "15  upto 15,000,000  \n",
       "16        6,000,000  \n",
       "17       10,670,000  \n",
       "18       16,200,000  \n",
       "19        5,000,000  \n",
       "20    1,200,000,000  \n",
       "21      100,000,000  \n",
       "22          934,160  \n",
       "23        1,700,000  \n",
       "24        3,300,000  \n",
       "25          400,000  \n",
       "26          974,200  \n",
       "27          292,800  \n",
       "28          200,000  \n",
       "29          500,000  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "Investments=pd.DataFrame({})\n",
    "Investments['Date']=Date[55:85]\n",
    "Investments['Startup']=Startup[55:85]\n",
    "Investments['Industry Vertical']=Industry_vertical[55:85]\n",
    "Investments['Sub Vertical']=Sub_vertical[55:85]\n",
    "Investments['City']=City[55:85]\n",
    "Investments['Investor Name']=Investor[55:85]\n",
    "Investments['Investment type']=Investment_type[55:85]\n",
    "Investments['Amount']=Fund[55:85]\n",
    "Investments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 7  digit.in \n",
    "driver=webdriver.Chrome(r\"C:\\Users\\INPshy\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.digit.in/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "laptop=driver.find_element_by_xpath('/html/body/div[1]/div[2]/div[4]/ul/li[3]/a')\n",
    "laptop.click()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestlaptop=driver.find_element_by_xpath('/html/body/div[6]/div/div[1]/div[4]/div/div/a[2]')\n",
    "bestlaptop.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.\\nAPPLE MACBOOK PRO 13-INCH M1',\n",
       " '2.\\nDELL XPS 13 (9310) - 2021',\n",
       " '3.\\nASUS ROG ZEPHYRUS G14',\n",
       " '4.\\nAPPLE MACBOOK AIR M1',\n",
       " '5.\\nHP SPECTRE X360 15-EB0014TX - 2021',\n",
       " '6.\\nASUS EXPERTBOOK B9 (B9400)',\n",
       " '7.\\nAPPLE MACBOOK PRO 16-INCH',\n",
       " '8.\\nACER ASPIRE 7 GAMING',\n",
       " '9.\\nLENOVO THINKPAD X1 EXTREME GEN 3',\n",
       " '10.\\nHP ENVY 15']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Laptop=[]\n",
    "try:\n",
    "    top=driver.find_elements_by_xpath('//div[@class=\"TopNumbeHeading active sticky-footer\"]')\n",
    "    for i in top:\n",
    "        Laptop.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Laptop.append('-')\n",
    "Laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NA',\n",
       " 'WINDOWS 10 HOME',\n",
       " 'WINDOWS 10 HOME',\n",
       " 'MACOS 10.14 MOJAVE',\n",
       " 'WINDOWS 10 PRO 64',\n",
       " 'WINDOWS 10 PRO',\n",
       " 'IOS',\n",
       " 'WINDOWS 10 HOME',\n",
       " 'WINDOWS 10 PRO',\n",
       " 'WINDOWS 10']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fetch OS\n",
    "OS=[]\n",
    "try:\n",
    "    os=driver.find_elements_by_xpath('//div[@class=\"product-detail\"]/div/ul/li[1]/div/div')\n",
    "    for j in os:\n",
    "        OS.append(j.text)\n",
    "except NoSuchElementException:\n",
    "    OS.append('-')\n",
    "OS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch Display\n",
    "Display=[]\n",
    "try:\n",
    "    display=driver.find_elements_by_xpath('//div[@class=\"product-detail\"]/div/ul/li[2]/div/div')\n",
    "    for k in display:\n",
    "        Display.append(k.text)\n",
    "except NoSuchElementException:\n",
    "    Display.append('-')\n",
    "Display\n",
    "#fetch Processor\n",
    "Processor=[]\n",
    "try:\n",
    "    processor=driver.find_elements_by_xpath('//div[@class=\"product-detail\"]/div/ul/li[3]/div/div')\n",
    "    for l in processor:\n",
    "        Processor.append(l.text)\n",
    "except NoSuchElementException:\n",
    "    Processor.append('-')\n",
    "    \n",
    "# fetch memory\n",
    "Memory=[]\n",
    "try:\n",
    "    memory=driver.find_elements_by_xpath('//div[@class=\"product-detail\"]/div/ul/li[4]/div/div')\n",
    "    for m in memory:\n",
    "        Memory.append(m.text)\n",
    "except NoSuchElementException:\n",
    "    Memory.append('-')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Laptop Name</th>\n",
       "      <th>OS</th>\n",
       "      <th>Display</th>\n",
       "      <th>Processor</th>\n",
       "      <th>Memory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.\\nAPPLE MACBOOK PRO 13-INCH M1</td>\n",
       "      <td>NA</td>\n",
       "      <td>13.3\" (2560 X 1600)</td>\n",
       "      <td>QUAD-CORE 8TH-GENERATION INTEL CORE I5 | 4.1 GHZ</td>\n",
       "      <td>256 GB SSD/8 GBGB DDR4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.\\nDELL XPS 13 (9310) - 2021</td>\n",
       "      <td>WINDOWS 10 HOME</td>\n",
       "      <td>13.4\" (3840 X 2400)</td>\n",
       "      <td>11TH GENERATION INTEL® CORE™ I7-1185G7 | NA</td>\n",
       "      <td>1 TB SSD/16 GBGB DDR4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.\\nASUS ROG ZEPHYRUS G14</td>\n",
       "      <td>WINDOWS 10 HOME</td>\n",
       "      <td>14\" (1920 X 1080)</td>\n",
       "      <td>AMD 3RD GENERATION RYZEN 9 | 3.3 GHZ</td>\n",
       "      <td>1 TB SSD/16 GBGB DDR4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.\\nAPPLE MACBOOK AIR M1</td>\n",
       "      <td>MACOS 10.14 MOJAVE</td>\n",
       "      <td>13.3\" (2560 X 1600)</td>\n",
       "      <td>8-CORE CPU | NA</td>\n",
       "      <td>256 GB SSD/8 GBGB DDR4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.\\nHP SPECTRE X360 15-EB0014TX - 2021</td>\n",
       "      <td>WINDOWS 10 PRO 64</td>\n",
       "      <td>15.6\" (3840 X 2160)</td>\n",
       "      <td>10TH GENERATION INTEL® CORE™ I7 -10750H | 2.6 GHZ</td>\n",
       "      <td>512 GB SSD/16 GBGB DDR4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.\\nASUS EXPERTBOOK B9 (B9400)</td>\n",
       "      <td>WINDOWS 10 PRO</td>\n",
       "      <td>14\" (1920 X 1080)</td>\n",
       "      <td>INTEL® CORE™ I7 11TH GEN-1165G7 | 2.8 GHZ</td>\n",
       "      <td>2 TB SSD/32 GBGB DDR4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.\\nAPPLE MACBOOK PRO 16-INCH</td>\n",
       "      <td>IOS</td>\n",
       "      <td>16\" (3072 X 1920)</td>\n",
       "      <td>INTEL CORE I9 8TH GEN | NA</td>\n",
       "      <td>512 GB SSD/16 GBGB DDR3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.\\nACER ASPIRE 7 GAMING</td>\n",
       "      <td>WINDOWS 10 HOME</td>\n",
       "      <td>15.6\" (1920 X 1080)</td>\n",
       "      <td>AMD RYZEN™ 5-5500U HEXA-CORE | NA</td>\n",
       "      <td>512 GB SSD/8 GBGB DDR4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.\\nLENOVO THINKPAD X1 EXTREME GEN 3</td>\n",
       "      <td>WINDOWS 10 PRO</td>\n",
       "      <td>15.6\" (1920 X 1080)</td>\n",
       "      <td>10TH GENERATION INTEL® CORE™ I7-10750H | 2.60 GHZ</td>\n",
       "      <td>512 GB SSD/8 GBGB DDR4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.\\nHP ENVY 15</td>\n",
       "      <td>WINDOWS 10</td>\n",
       "      <td>15\" (1920 X 1080)</td>\n",
       "      <td>INTEL I7-10750H 10TH GEN | 2.6 GHZ</td>\n",
       "      <td>1 TB SSD/16 GBGB DDR4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Laptop Name                  OS  \\\n",
       "0        1.\\nAPPLE MACBOOK PRO 13-INCH M1                  NA   \n",
       "1           2.\\nDELL XPS 13 (9310) - 2021     WINDOWS 10 HOME   \n",
       "2               3.\\nASUS ROG ZEPHYRUS G14     WINDOWS 10 HOME   \n",
       "3                4.\\nAPPLE MACBOOK AIR M1  MACOS 10.14 MOJAVE   \n",
       "4  5.\\nHP SPECTRE X360 15-EB0014TX - 2021   WINDOWS 10 PRO 64   \n",
       "5          6.\\nASUS EXPERTBOOK B9 (B9400)      WINDOWS 10 PRO   \n",
       "6           7.\\nAPPLE MACBOOK PRO 16-INCH                 IOS   \n",
       "7                8.\\nACER ASPIRE 7 GAMING     WINDOWS 10 HOME   \n",
       "8    9.\\nLENOVO THINKPAD X1 EXTREME GEN 3      WINDOWS 10 PRO   \n",
       "9                         10.\\nHP ENVY 15          WINDOWS 10   \n",
       "\n",
       "               Display                                          Processor  \\\n",
       "0  13.3\" (2560 X 1600)   QUAD-CORE 8TH-GENERATION INTEL CORE I5 | 4.1 GHZ   \n",
       "1  13.4\" (3840 X 2400)        11TH GENERATION INTEL® CORE™ I7-1185G7 | NA   \n",
       "2    14\" (1920 X 1080)               AMD 3RD GENERATION RYZEN 9 | 3.3 GHZ   \n",
       "3  13.3\" (2560 X 1600)                                    8-CORE CPU | NA   \n",
       "4  15.6\" (3840 X 2160)  10TH GENERATION INTEL® CORE™ I7 -10750H | 2.6 GHZ   \n",
       "5    14\" (1920 X 1080)          INTEL® CORE™ I7 11TH GEN-1165G7 | 2.8 GHZ   \n",
       "6    16\" (3072 X 1920)                         INTEL CORE I9 8TH GEN | NA   \n",
       "7  15.6\" (1920 X 1080)                  AMD RYZEN™ 5-5500U HEXA-CORE | NA   \n",
       "8  15.6\" (1920 X 1080)  10TH GENERATION INTEL® CORE™ I7-10750H | 2.60 GHZ   \n",
       "9    15\" (1920 X 1080)                 INTEL I7-10750H 10TH GEN | 2.6 GHZ   \n",
       "\n",
       "                    Memory  \n",
       "0   256 GB SSD/8 GBGB DDR4  \n",
       "1    1 TB SSD/16 GBGB DDR4  \n",
       "2    1 TB SSD/16 GBGB DDR4  \n",
       "3   256 GB SSD/8 GBGB DDR4  \n",
       "4  512 GB SSD/16 GBGB DDR4  \n",
       "5    2 TB SSD/32 GBGB DDR4  \n",
       "6  512 GB SSD/16 GBGB DDR3  \n",
       "7   512 GB SSD/8 GBGB DDR4  \n",
       "8   512 GB SSD/8 GBGB DDR4  \n",
       "9    1 TB SSD/16 GBGB DDR4  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Top_laptop=pd.DataFrame({})\n",
    "Top_laptop['Laptop Name']=Laptop\n",
    "Top_laptop['OS']=OS\n",
    "Top_laptop['Display']=Display\n",
    "Top_laptop['Processor']=Processor\n",
    "Top_laptop['Memory']=Memory\n",
    "Top_laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8lets first connect with webdriver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\INPshy\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.forbes.com/?sh=1e9f7ea42254'\n",
    "driver.get(url)\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "button=driver.find_element_by_xpath('//button[@class=\"icon--hamburger\"]')\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "billionairs=driver.find_element_by_xpath('//li[@class=\"header__channel header__color--centennial-silver header__hoverable\"]')\n",
    "billionairs.click()\n",
    "worldbillanior=driver.find_element_by_xpath('//li[@class=\"header__section\"]')\n",
    "worldbillanior.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rank=[]\n",
    "Name=[]\n",
    "Networth=[]\n",
    "Country=[]\n",
    "Source=[]\n",
    "Industry=[]\n",
    "#fetch Rank\n",
    "try:\n",
    "    rank=driver.find_elements_by_xpath('//div[@class=\"rank\"]')\n",
    "    for k in rank:\n",
    "        Rank.append(k.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append('-')\n",
    "#fetch person Name\n",
    "try:\n",
    "    name=driver.find_elements_by_xpath('//div[@class=\"personName\"]')\n",
    "    for l in name:\n",
    "        Name.append(l.text)\n",
    "except NoSuchElementException:\n",
    "    Name.append('-')\n",
    "#fetch Newtworth\n",
    "try:\n",
    "    networth=driver.find_elements_by_xpath('//div[@class=\"netWorth\"]')\n",
    "    for m in networth:\n",
    "        Networth.append(m.text)\n",
    "except NoSuchElementException:\n",
    "    Networth.append('-')\n",
    "#fetch country\n",
    "try:\n",
    "    country=driver.find_elements_by_xpath('//div[@class=\"countryOfCitizenship\"]')\n",
    "    for n in country:\n",
    "        Country.append(n.text)\n",
    "except NoSuchElementException:\n",
    "    Country.append('-')\n",
    "#fetch Source\n",
    "try:\n",
    "    source=driver.find_elements_by_xpath('//div[@class=\"source-column\"]')\n",
    "    for o in source:\n",
    "        Source.append(o.text)\n",
    "except NoSuchElementException:\n",
    "    Source.append('-')\n",
    "Industry=[]\n",
    "#fetch Industry:\n",
    "try:\n",
    "    industry=driver.find_elements_by_xpath('//div[@class=\"category\"]')\n",
    "    for p in industry:\n",
    "        Industry.append(p.text)\n",
    "except NoSuchElementException:\n",
    "    Industry.append('_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 200 200 200 200 200\n"
     ]
    }
   ],
   "source": [
    "print(len(Rank),len(Name),len(Networth),len(Country),len(Source),len(Industry))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Networth</th>\n",
       "      <th>country</th>\n",
       "      <th>Source</th>\n",
       "      <th>Industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>Jeff Bezos</td>\n",
       "      <td>$177 B</td>\n",
       "      <td>United States</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>$151 B</td>\n",
       "      <td>United States</td>\n",
       "      <td>Tesla, SpaceX</td>\n",
       "      <td>Automotive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>Bernard Arnault &amp; family</td>\n",
       "      <td>$150 B</td>\n",
       "      <td>France</td>\n",
       "      <td>LVMH</td>\n",
       "      <td>Fashion &amp; Retail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>Bill Gates</td>\n",
       "      <td>$124 B</td>\n",
       "      <td>United States</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>Mark Zuckerberg</td>\n",
       "      <td>$97 B</td>\n",
       "      <td>United States</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>195.</td>\n",
       "      <td>Harry Triguboff</td>\n",
       "      <td>$11.2 B</td>\n",
       "      <td>Australia</td>\n",
       "      <td>real estate</td>\n",
       "      <td>Real Estate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>197.</td>\n",
       "      <td>Leonid Fedun &amp; family</td>\n",
       "      <td>$11.1 B</td>\n",
       "      <td>Russia</td>\n",
       "      <td>oil</td>\n",
       "      <td>Energy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>197.</td>\n",
       "      <td>Eyal Ofer</td>\n",
       "      <td>$11.1 B</td>\n",
       "      <td>Israel</td>\n",
       "      <td>real estate, shipping</td>\n",
       "      <td>Diversified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>197.</td>\n",
       "      <td>Evan Spiegel</td>\n",
       "      <td>$11.1 B</td>\n",
       "      <td>United States</td>\n",
       "      <td>Snapchat</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>200.</td>\n",
       "      <td>Luis Carlos Sarmiento</td>\n",
       "      <td>$11 B</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>banking</td>\n",
       "      <td>Finance &amp; Investments</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Rank                      Name Networth        country  \\\n",
       "0      1.                Jeff Bezos   $177 B  United States   \n",
       "1      2.                 Elon Musk   $151 B  United States   \n",
       "2      3.  Bernard Arnault & family   $150 B         France   \n",
       "3      4.                Bill Gates   $124 B  United States   \n",
       "4      5.           Mark Zuckerberg    $97 B  United States   \n",
       "..    ...                       ...      ...            ...   \n",
       "195  195.           Harry Triguboff  $11.2 B      Australia   \n",
       "196  197.     Leonid Fedun & family  $11.1 B         Russia   \n",
       "197  197.                 Eyal Ofer  $11.1 B         Israel   \n",
       "198  197.              Evan Spiegel  $11.1 B  United States   \n",
       "199  200.     Luis Carlos Sarmiento    $11 B       Colombia   \n",
       "\n",
       "                    Source               Industry  \n",
       "0                   Amazon             Technology  \n",
       "1            Tesla, SpaceX             Automotive  \n",
       "2                     LVMH       Fashion & Retail  \n",
       "3                Microsoft             Technology  \n",
       "4                 Facebook             Technology  \n",
       "..                     ...                    ...  \n",
       "195            real estate            Real Estate  \n",
       "196                    oil                 Energy  \n",
       "197  real estate, shipping            Diversified  \n",
       "198               Snapchat             Technology  \n",
       "199                banking  Finance & Investments  \n",
       "\n",
       "[200 rows x 6 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Billionairs=pd.DataFrame({})\n",
    "Billionairs['Rank']=Rank\n",
    "Billionairs['Name']=Name\n",
    "Billionairs['Networth']=Networth\n",
    "Billionairs['country']=Country\n",
    "Billionairs['Source']=Source\n",
    "Billionairs['Industry']=Industry\n",
    "Billionairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9 Youtube comment,lets first connect with webdriver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\INPshy\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.youtube.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "invetion=driver.find_element_by_xpath('/html/body/ytd-app/div/ytd-page-manager/ytd-browse/ytd-two-column-browse-results-renderer/div[1]/ytd-rich-grid-renderer/div[6]/ytd-rich-item-renderer[3]/div/ytd-rich-grid-media/div[1]/ytd-thumbnail/a/yt-img-shadow/img')\n",
    "invetion.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scroll down for more comment\n",
    "for _ in range(1000):\n",
    "    driver.execute_script(\"window.scrollBy(0,20000)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Comment=[]\n",
    "Upvote=[]\n",
    "Time=[]\n",
    "#fetch comment\n",
    "try:\n",
    "    comment=driver.find_elements_by_xpath('//yt-formatted-string[@class=\"style-scope ytd-comment-renderer\"]')\n",
    "    for i in comment:\n",
    "        Comment.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Comment.append('-')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Upvote=[]\n",
    "#fetch upvote\n",
    "try:\n",
    "    upvote=driver.find_elements_by_xpath('//div[@class=\"style-scope ytd-comment-action-buttons-renderer\"]/span')\n",
    "    for j in upvote:\n",
    "        Upvote.append(j.text)\n",
    "except NoSuchElementException:\n",
    "    Upvote.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "678"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "678"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Upvote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    time=driver.find_elements_by_xpath('//yt-formatted-string[@class=\"published-time-text above-comment style-scope ytd-comment-renderer\"]')\n",
    "    for k in time:\n",
    "        Time.append(k.text)\n",
    "except NoSuchElementException:\n",
    "    Time.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "678"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Upvote</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>6 days ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>❤❤❤❤🥰🥰🥰🥰</td>\n",
       "      <td>1</td>\n",
       "      <td>3 days ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>20 hours ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Excellent!!</td>\n",
       "      <td>1</td>\n",
       "      <td>3 months ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3 months ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>Arijit Singh beautiful Gentleman ❤️ with golde...</td>\n",
       "      <td>6</td>\n",
       "      <td>5 months ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>5 months ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>I live arjit singh</td>\n",
       "      <td></td>\n",
       "      <td>6 months ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3 months ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>Very nice song Arijit Singh</td>\n",
       "      <td>4</td>\n",
       "      <td>2 months ago</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>678 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Comment Upvote          Time\n",
       "0                                                                6 days ago\n",
       "1                                             ❤❤❤❤🥰🥰🥰🥰      1    3 days ago\n",
       "2                                                              20 hours ago\n",
       "3                                          Excellent!!      1  3 months ago\n",
       "4                                                              3 months ago\n",
       "..                                                 ...    ...           ...\n",
       "673  Arijit Singh beautiful Gentleman ❤️ with golde...      6  5 months ago\n",
       "674                                                            5 months ago\n",
       "675                                 I live arjit singh         6 months ago\n",
       "676                                                            3 months ago\n",
       "677                        Very nice song Arijit Singh      4  2 months ago\n",
       "\n",
       "[678 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Youtube=pd.DataFrame({})\n",
    "Youtube['Comment']=Comment\n",
    "Youtube['Upvote']=Upvote\n",
    "Youtube['Time']=Time\n",
    "Youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10 Hostelworl,lets first connect with webdriver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\INPshy\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.hostelworld.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element_by_id('search-input-field')\n",
    "search.send_keys('London')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "london=driver.find_element_by_xpath('//div[@class=\"label\"]')\n",
    "london.click()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "letsgo=driver.find_element_by_id('search-button')\n",
    "letsgo.click()\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hotel_Name=[]\n",
    "try:\n",
    "    hotel=driver.find_elements_by_xpath('//h2[@class=\"title title-6\"]')\n",
    "    for i in hotel:\n",
    "        Hotel_Name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Hotel_Name.append('-')\n",
    "len(Hotel_Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fetch Distance from city\n",
    "Distance_city=[]\n",
    "try:\n",
    "    distance=driver.find_elements_by_xpath('//span[@class=\"description\"]')\n",
    "    for i in distance:\n",
    "        Distance_city.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Distance_city.append('-')\n",
    "len(Distance_city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8.6',\n",
       " '8.9',\n",
       " '7.4',\n",
       " '8.9',\n",
       " '8.0',\n",
       " '8.9',\n",
       " '9.3',\n",
       " '8.5',\n",
       " '8.9',\n",
       " 'NEW\\n0 Total Reviews',\n",
       " '8.3',\n",
       " '7.6',\n",
       " '9.1',\n",
       " '8.6',\n",
       " '10',\n",
       " '7.3',\n",
       " '7.7',\n",
       " '7.3',\n",
       " '6.8',\n",
       " '7.5',\n",
       " '8.7',\n",
       " '6.9',\n",
       " '6.0',\n",
       " '8.9',\n",
       " '8.0',\n",
       " '8.2',\n",
       " '8.9',\n",
       " '8.2',\n",
       " '9.7',\n",
       " '8.3']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rating\n",
    "Rating=[]\n",
    "try:\n",
    "    rating=driver.find_elements_by_xpath('//div[@class=\"info\"]/a/div/div[1]')\n",
    "    for i in rating:\n",
    "        Rating.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rating.append('-')\n",
    "len(Rating)\n",
    "Rating[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fabulous',\n",
       " 'Fabulous',\n",
       " 'Very Good',\n",
       " 'Fabulous',\n",
       " 'Fabulous',\n",
       " 'Fabulous',\n",
       " 'Superb',\n",
       " 'Fabulous',\n",
       " 'Fabulous',\n",
       " 'NEW',\n",
       " 'Fabulous',\n",
       " 'Very Good',\n",
       " 'Superb',\n",
       " 'Fabulous',\n",
       " 'Superb',\n",
       " 'Very Good',\n",
       " 'Very Good',\n",
       " 'Very Good',\n",
       " 'Good',\n",
       " 'Very Good',\n",
       " 'Fabulous',\n",
       " 'Good',\n",
       " 'Good',\n",
       " 'Fabulous',\n",
       " 'Fabulous',\n",
       " 'Fabulous',\n",
       " 'Fabulous',\n",
       " 'Fabulous',\n",
       " 'Superb',\n",
       " 'Fabulous']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#review\n",
    "Review=[]\n",
    "try:\n",
    "    review=driver.find_elements_by_xpath('//div[@class=\"info\"]/a/div/div/div[1]/span[1]')\n",
    "    for i in review:\n",
    "        Review.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Review.append('-')\n",
    "Review[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#overall review\n",
    "Overall_review=[]\n",
    "try:\n",
    "    overall_review=driver.find_elements_by_xpath('//div[@class=\"reviews\"]')\n",
    "    for i in overall_review:\n",
    "        Overall_review.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Overall_review.append('-')\n",
    "len(Overall_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#private from \n",
    "Private=[]\n",
    "try:\n",
    "    private=driver.find_elements_by_xpath('//div[@class=\"prices-col\"]/a/div[1]')\n",
    "    for i in private:\n",
    "        Private.append(i.text.replace('Privates From\\n',','))\n",
    "except:\n",
    "    Private.append('-')\n",
    "len(Private)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dorms from \n",
    "Dorms=[]\n",
    "try:\n",
    "    dorms=driver.find_elements_by_xpath('//div[@class=\"prices-col\"]/a/div[2]')\n",
    "    for i in dorms:\n",
    "        Dorms.append(i.text.replace('Dorms From\\n',','))\n",
    "except:\n",
    "    Dorms.append('-')\n",
    "len(Dorms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fetch Distance from city\n",
    "Distance_city=[]\n",
    "try:\n",
    "    distance=driver.find_elements_by_xpath('//span[@class=\"description\"]')\n",
    "    for i in distance:\n",
    "        Distance_city.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Distance_city.append('-')\n",
    "len(Distance_city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Dorms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#page 2 data\n",
    "next_button = driver.find_element_by_xpath('//div[@class=\"pagination-item pagination-next\"]')\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#private from page 2\n",
    "Private2=[]\n",
    "try:\n",
    "    private=driver.find_elements_by_xpath('//div[@class=\"prices-col\"]/a/div[1]')\n",
    "    for i in private:\n",
    "        Private2.append(i.text.replace('Privates From\\n',','))\n",
    "except:\n",
    "    Private2.append('-')\n",
    "len(Private2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dorms from page 2\n",
    "Dorms2=[]\n",
    "try:\n",
    "    dorms=driver.find_elements_by_xpath('//div[@class=\"prices-col\"]/a/div[2]')\n",
    "    for i in dorms:\n",
    "        Dorms2.append(i.text.replace('Dorms From\\n',','))\n",
    "except:\n",
    "    Dorms2.append('-')\n",
    "len(Dorms2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fetch Distance from city\n",
    "Distance_city2=[]\n",
    "try:\n",
    "    distance=driver.find_elements_by_xpath('//span[@class=\"description\"]')\n",
    "    for i in distance:\n",
    "        Distance_city2.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Distance_city2.append('-')\n",
    "len(Distance_city2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#page 3 data\n",
    "next_button = driver.find_element_by_xpath('//div[@class=\"pagination-item pagination-next\"]')\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#private from page 3\n",
    "Private3=[]\n",
    "try:\n",
    "    private=driver.find_elements_by_xpath('//div[@class=\"prices-col\"]/a/div[1]')\n",
    "    for i in private:\n",
    "        Private3.append(i.text.replace('Privates From\\n',','))\n",
    "except:\n",
    "    Private3.append('-')\n",
    "len(Private3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dorms from page 3\n",
    "Dorms3=[]\n",
    "try:\n",
    "    dorms=driver.find_elements_by_xpath('//div[@class=\"prices-col\"]/a/div[2]')\n",
    "    for i in dorms:\n",
    "        Dorms3.append(i.text.replace('Dorms From\\n',','))\n",
    "except:\n",
    "    Dorms3.append('-')\n",
    "len(Dorms3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fetch Distance from city page 3\n",
    "Distance_city3=[]\n",
    "try:\n",
    "    distance=driver.find_elements_by_xpath('//span[@class=\"description\"]')\n",
    "    for i in distance:\n",
    "        Distance_city3.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Distance_city3.append('-')\n",
    "len(Distance_city3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add all private price\n",
    "Private_rate=Private+Private2+Private3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add all dorms price\n",
    "Dorms_rate=Dorms+Dorms2+Dorms3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add all distance\n",
    "Distance=Distance_city+Distance_city2+Distance_city3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#back to page 1 for inside data fetching\n",
    "page1=driver.find_element_by_xpath('//div[@class=\"pagination-item\"]')\n",
    "page1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make empty lists\n",
    "Hostel_Name = []\n",
    "Distance = []\n",
    "overall_review = []\n",
    "total_reviews = []\n",
    "facilities = []\n",
    "price = []\n",
    "Rating = []\n",
    "property_description = []\n",
    "Comment=[]\n",
    "Review=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# scrape Hostels URL\n",
    "hostel_url = []\n",
    "\n",
    "while(True):\n",
    "    urls = driver.find_elements_by_xpath('//h2[@class=\"title title-6\"]//a')\n",
    "    for url in urls:\n",
    "        hostel_url.append(url.get_attribute(\"href\"))\n",
    "    time.sleep(2)    \n",
    "        \n",
    "    try:\n",
    "        next_button = driver.find_element_by_xpath('//div[@class=\"pagination-item pagination-next\"]')\n",
    "        next_button.click()\n",
    "    except:\n",
    "        break\n",
    "\n",
    "\n",
    "         \n",
    "for page in hostel_url:\n",
    "    driver.get(page)\n",
    "    #fetch Hotel Name\n",
    "    try:\n",
    "        hostel = driver.find_element_by_xpath('//div[@class=\"title-2\"]')\n",
    "        Hostel_Name.append(hostel.text)\n",
    "    except NoSuchElementException:\n",
    "        Hostel_Name.append(\"No Rating\")  \n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Rating\n",
    "    try:\n",
    "        ratings = driver.find_element_by_xpath('//div[@class=\"score orange big\"]')\n",
    "        Rate.append(ratings.text)\n",
    "    except NoSuchElementException:\n",
    "        Rate.append(\"No Rating\")  \n",
    "    time.sleep(2)\n",
    "#fetch comment    \n",
    " \n",
    "    try:\n",
    "        cm = driver.find_element_by_xpath('//div[@class=\"keyword\"]')\n",
    "        Comment.append(cm.text)\n",
    "    except NoSuchElementException:\n",
    "        Comment.append(\"NO comment\")  \n",
    "    time.sleep(2)\n",
    "#fect Review\n",
    "\n",
    "\n",
    "    try:\n",
    "        review = driver.find_element_by_xpath('//div[@class=\"reviews\"]')\n",
    "        Review.append(review.text)\n",
    "    except NoSuchElementException:\n",
    "        Review.append(\"NO review\")  \n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Property Description\n",
    "    try:\n",
    "        pd = driver.find_element_by_xpath('//div[@class=\"content collapse-content\"]')\n",
    "        property_description.append(pd.text)\n",
    "    except NoSuchElementException:\n",
    "        property_description.append(\"No Description\") \n",
    "    \n",
    "\n",
    "    \n",
    "time.sleep(2)        \n",
    "# remove extra data from Rating     \n",
    "all_text = []\n",
    "for i in Rate:\n",
    "    all_text.append(i.split())\n",
    "time.sleep(2)\n",
    "\n",
    "for i in all_text:\n",
    "    Rating.append(i[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(property_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hostel Name</th>\n",
       "      <th>Private Rate</th>\n",
       "      <th>Dorms Rate</th>\n",
       "      <th>Distance_city</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Review</th>\n",
       "      <th>Property_discription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Walrus Hostel</td>\n",
       "      <td>No Privates Available</td>\n",
       "      <td>,Rs1292</td>\n",
       "      <td>Hostel - 5km from city centre</td>\n",
       "      <td>8.8</td>\n",
       "      <td>Fabulous</td>\n",
       "      <td>3638 Total Reviews</td>\n",
       "      <td>The hotel has modern security, all the doors h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SoHostel</td>\n",
       "      <td>No Privates Available</td>\n",
       "      <td>,Rs2050</td>\n",
       "      <td>Hostel - 1.7km from city centre</td>\n",
       "      <td>7.6</td>\n",
       "      <td>Superb</td>\n",
       "      <td>3951 Total Reviews</td>\n",
       "      <td>*Hostel Update*\\nOur doors will remain open to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PubLove @ The Rose &amp; Crown</td>\n",
       "      <td>No Privates Available</td>\n",
       "      <td>,Rs1538</td>\n",
       "      <td>Hostel - 3.3km from city centre</td>\n",
       "      <td>9.8</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>99 Total Reviews</td>\n",
       "      <td>Food &amp; culture lovers, assemble!\\nThe Rose &amp; C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>St Christopher's Village</td>\n",
       "      <td>,Rs3930</td>\n",
       "      <td>,Rs1510</td>\n",
       "      <td>Hostel - 2.2km from city centre</td>\n",
       "      <td>6.8</td>\n",
       "      <td>Fabulous</td>\n",
       "      <td>10819 Total Reviews</td>\n",
       "      <td>COVID 19 Policy Update.\\nIn response to Corona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>London Waterloo Hostel</td>\n",
       "      <td>No Privates Available</td>\n",
       "      <td>,Rs1338</td>\n",
       "      <td>Hostel - 6.3km from city centre</td>\n",
       "      <td>No</td>\n",
       "      <td>Fabulous</td>\n",
       "      <td>2400 Total Reviews</td>\n",
       "      <td>COVID-19 Policy Update\\n\\nIn response to Coron...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>The W14 Hotel &amp; Bar</td>\n",
       "      <td>,Rs7074</td>\n",
       "      <td>No Dorms Available</td>\n",
       "      <td>Hotel - 6.5km from city centre</td>\n",
       "      <td>No</td>\n",
       "      <td>Superb</td>\n",
       "      <td>276 Total Reviews</td>\n",
       "      <td>The W14 Hotel London is a 3 star Superior Budg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Best Western Boltons London Kensington</td>\n",
       "      <td>,Rs10609</td>\n",
       "      <td>No Dorms Available</td>\n",
       "      <td>Hotel - 5.4km from city centre</td>\n",
       "      <td>No</td>\n",
       "      <td>Rating</td>\n",
       "      <td>2 Total Reviews</td>\n",
       "      <td>Combining Victorian charm with Modern Luxury T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Park Hotel Essex</td>\n",
       "      <td>,Rs3793</td>\n",
       "      <td>No Dorms Available</td>\n",
       "      <td>Hotel - 24.1km from city centre</td>\n",
       "      <td>No</td>\n",
       "      <td>No Rating</td>\n",
       "      <td>0 Total Reviews</td>\n",
       "      <td>This Hotel is the right choice for visitors wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Cranbrook Hotel</td>\n",
       "      <td>,Rs3691</td>\n",
       "      <td>No Dorms Available</td>\n",
       "      <td>Hotel - 14.8km from city centre</td>\n",
       "      <td>No</td>\n",
       "      <td>No Rating</td>\n",
       "      <td>0 Total Reviews</td>\n",
       "      <td>We are located about twenty minutes by tube fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>St. Athans</td>\n",
       "      <td>,Rs3868</td>\n",
       "      <td>No Dorms Available</td>\n",
       "      <td>Bed and Breakfast - 2.9km from city centre</td>\n",
       "      <td>No</td>\n",
       "      <td>No Rating</td>\n",
       "      <td>0 Total Reviews</td>\n",
       "      <td>The St Athans Hotel is a proudly simple, famil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Hostel Name           Private Rate  \\\n",
       "0                        The Walrus Hostel  No Privates Available   \n",
       "1                                 SoHostel  No Privates Available   \n",
       "2               PubLove @ The Rose & Crown  No Privates Available   \n",
       "3                 St Christopher's Village                ,Rs3930   \n",
       "4                   London Waterloo Hostel  No Privates Available   \n",
       "..                                     ...                    ...   \n",
       "85                     The W14 Hotel & Bar                ,Rs7074   \n",
       "86  Best Western Boltons London Kensington               ,Rs10609   \n",
       "87                        Park Hotel Essex                ,Rs3793   \n",
       "88                         Cranbrook Hotel                ,Rs3691   \n",
       "89                              St. Athans                ,Rs3868   \n",
       "\n",
       "            Dorms Rate                               Distance_city Rating  \\\n",
       "0              ,Rs1292               Hostel - 5km from city centre    8.8   \n",
       "1              ,Rs2050             Hostel - 1.7km from city centre    7.6   \n",
       "2              ,Rs1538             Hostel - 3.3km from city centre    9.8   \n",
       "3              ,Rs1510             Hostel - 2.2km from city centre    6.8   \n",
       "4              ,Rs1338             Hostel - 6.3km from city centre     No   \n",
       "..                 ...                                         ...    ...   \n",
       "85  No Dorms Available              Hotel - 6.5km from city centre     No   \n",
       "86  No Dorms Available              Hotel - 5.4km from city centre     No   \n",
       "87  No Dorms Available             Hotel - 24.1km from city centre     No   \n",
       "88  No Dorms Available             Hotel - 14.8km from city centre     No   \n",
       "89  No Dorms Available  Bed and Breakfast - 2.9km from city centre     No   \n",
       "\n",
       "      Comment               Review  \\\n",
       "0    Fabulous   3638 Total Reviews   \n",
       "1      Superb   3951 Total Reviews   \n",
       "2   Very Good     99 Total Reviews   \n",
       "3    Fabulous  10819 Total Reviews   \n",
       "4    Fabulous   2400 Total Reviews   \n",
       "..        ...                  ...   \n",
       "85     Superb    276 Total Reviews   \n",
       "86     Rating      2 Total Reviews   \n",
       "87  No Rating      0 Total Reviews   \n",
       "88  No Rating      0 Total Reviews   \n",
       "89  No Rating      0 Total Reviews   \n",
       "\n",
       "                                 Property_discription  \n",
       "0   The hotel has modern security, all the doors h...  \n",
       "1   *Hostel Update*\\nOur doors will remain open to...  \n",
       "2   Food & culture lovers, assemble!\\nThe Rose & C...  \n",
       "3   COVID 19 Policy Update.\\nIn response to Corona...  \n",
       "4   COVID-19 Policy Update\\n\\nIn response to Coron...  \n",
       "..                                                ...  \n",
       "85  The W14 Hotel London is a 3 star Superior Budg...  \n",
       "86  Combining Victorian charm with Modern Luxury T...  \n",
       "87  This Hotel is the right choice for visitors wh...  \n",
       "88  We are located about twenty minutes by tube fr...  \n",
       "89  The St Athans Hotel is a proudly simple, famil...  \n",
       "\n",
       "[90 rows x 8 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hostel=pd.DataFrame({})\n",
    "Hostel['Hostel Name']=Hostel_Name[:90]\n",
    "Hostel['Private Rate']=Private_rate[:90]\n",
    "Hostel['Dorms Rate']=Dorms_rate[:90]\n",
    "Hostel['Distance_city']=Distance[:90]\n",
    "Hostel['Rating']=Rating[:90]\n",
    "Hostel['Comment']=Comment[:90]\n",
    "Hostel['Review']=Review[:90]\n",
    "Hostel['Property_discription']=property_description[:90]\n",
    "Hostel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
